{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# ETHZ: 227-0966-00L\n",
    "# Quantitative Big Imaging\n",
    "# March 12, 2020\n",
    "\n",
    "## Basic Segmentation and Discrete Binary Structures\n",
    "### Part 1\n",
    "\n",
    "### Anders Kaestner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lesson Outline\n",
    "- Motivation\n",
    "- Qualitative Approaches\n",
    "- Thresholding\n",
    " - Other types of images\n",
    " - Selecting a good threshold\n",
    "- Implementation\n",
    "- Morphology\n",
    "- Contouring / Mask Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Applications\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "        \n",
    "- Simple two-phase materials (bone, cells, etc)\n",
    "  - Beyond 1 channel of depth\n",
    "- Multiple phase materials\n",
    "- Filling holes in materials\n",
    "- Segmenting Fossils\n",
    "- Attempting to segment the cortex in brain imaging\n",
    "\n",
    "</td>\n",
    "<td>\n",
    "<figure>\n",
    "    \n",
    "![Cortex Image](ext-figures/cortex.png)\n",
    "        <figcaption>The cortex in brain imaging</figcaption>\n",
    "</figure>\n",
    "</td></tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Literature / Useful References\n",
    "\n",
    "- John C. Russ, “The Image Processing Handbook”,(Boca Raton, CRC Press)\n",
    " - Available [online](http://dx.doi.org/10.1201/9780203881095) within domain ethz.ch (or proxy.ethz.ch / public VPN) \n",
    "\n",
    "### Models / ROC Curves\n",
    "\n",
    "- [Julia Evans - Recalling with Precision](https://www.youtube.com/watch?v=ryZL4XNUmwo)\n",
    "- [Stripe's Next Top Model](https://github.com/stripe/topmodel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Motivation:  Why do we do imaging experiments?\n",
    "\n",
    "## Exploratory\n",
    " - To visually, qualitatively examine samples and differences between them\n",
    " - No prior knowledge or expectations\n",
    " \n",
    "## To test a hypothesis\n",
    "Quantitative assessment coupled with statistical analysis\n",
    " - Does temperature affect bubble size?\n",
    " - Is this gene important for cell shape and thus mechanosensation in bone?\n",
    " - Does higher canal volume make bones weaker?\n",
    " - Does the granule shape affect battery life expectancy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## What we are looking at?\n",
    "![Standard Cell, http://en.wikipedia.org/wiki/File:Average_prokaryote_cell-_en.svg](ext-figures/Average_prokaryote_cell.svg) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## What we get from the imaging modality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from skimage.io import imread\n",
    "from skimage.color import rgb2gray\n",
    "import matplotlib.pyplot as plt\n",
    "dkimg = imread(\"../common/figures/Average_prokaryote_cell.jpg\")\n",
    "plt.matshow(rgb2gray(dkimg), cmap = 'bone')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# To test a hypothesis\n",
    "\n",
    "We perform an experiment bone to see how big the cells are inside the tissue:\n",
    "\n",
    "    \n",
    "$$\\downarrow$$ \n",
    "    \n",
    "<img src=\"ext-figures/tomoimage.png\" style=\"height:200px\"> \n",
    "\n",
    "### <center>2560 x 2560 x 2160 x 32 bit = 56GB / sample</center>\n",
    "    \n",
    "<center>Filtering and Preprocessing!  </center>\n",
    "    \n",
    "$$\\downarrow$$\n",
    "\n",
    "### <center>20h of computer time later ...</center>\n",
    "\n",
    "<center>Still 56GB of data, but less noisy</center>\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<center>\n",
    "    \n",
    "### Way too much data, we need to reduce\n",
    "    \n",
    "</center>\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# What did we want in the first place?\n",
    "\n",
    "\n",
    "### *Single numbers*:\n",
    "* volume fraction,\n",
    "* cell count,\n",
    "* average cell stretch,\n",
    "* cell volume variability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Why do we perform segmentation?\n",
    "\n",
    "- In model-based analysis every step we peform, simple or complicated is related to an underlying model of the system we are dealing with\n",
    "- [_Occam's Razor_](http://en.wikipedia.org/wiki/Occams_Razor) is very important here : The simplest solution is usually the right one\n",
    " - Bayesian, neural networks optimized using genetic algorithms with Fuzzy logic has a much larger parameter space to explore, establish sensitivity in, and must perform much better and be tested much more thoroughly than thresholding to be justified.\n",
    " - We will cover some of these techniques in the next 2 lectures since they can be very powerful particularly with unknown data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Review: Filtering and Image Enhancement (last week)\n",
    "\n",
    "\n",
    "This was a noise process which was added to otherwise clean imaging data\n",
    "\n",
    "<center><img src=\"ext-figures/lecture03/imperfect_imaging_system.svg\" style=\"height:150px\" align=\"middle\"></center>\n",
    "\n",
    "$$ I_{measured}(x,y) = I_{sample}(x,y) + \\text{Noise}(x,y) $$\n",
    "\n",
    "- What would the perfect filter be\n",
    "\n",
    "$$ \\textit{Filter} \\ast I_{sample}(x,y) = I_{sample}(x,y) $$\n",
    " $$ \\textit{Filter} \\ast \\text{Noise}(x,y) = 0 $$ \n",
    " $$ \\textit{Filter} \\ast I_{measured}(x,y) = \\textit{Filter} \\ast I_{real}(x,y) + \\textit{Filter}\\ast \\text{Noise}(x,y) \\rightarrow \\bf I_{sample}(x,y) $$\n",
    "\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "What __most filters__ end up doing\n",
    "$$ \\textit{Filter} \\ast I_{measured}(x,y) = 90\\%  I_{real}(x,y) + 10\\% \\text{Noise}(x,y) $$\n",
    "    \n",
    "</div> \n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "\n",
    "What __bad filters__ do\n",
    "$$ \\textit{Filter} \\ast I_{measured}(x,y) = 10\\% I_{real}(x,y) + 90\\% \\text{Noise}(x,y) $$\n",
    "    \n",
    "</div> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Qualitative Metrics: What did people use to do?\n",
    "- What comes out of our detector / enhancement process "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from skimage.io import imread\n",
    "from skimage.color import rgb2gray\n",
    "import matplotlib.pyplot as plt\n",
    "dkimg = rgb2gray(imread(\"../common/figures/Average_prokaryote_cell.jpg\"))\n",
    "fig, (ax_hist, ax_img) = plt.subplots(1, 2, figsize = (12,3))\n",
    "\n",
    "ax_hist.hist(dkimg.ravel())\n",
    "ax_hist.set_xlabel('Absorption Coefficient')\n",
    "ax_hist.set_ylabel('Pixel Count')\n",
    "\n",
    "m_show_obj = ax_img.matshow(dkimg, cmap = 'bone')\n",
    "cb_obj = plt.colorbar(m_show_obj)\n",
    "cb_obj.set_label('Absorption Coefficient')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Identify objects by eye\n",
    " - Count, describe qualitatively: \"many little cilia on surface\", \"long curly flaggelum\", \"elongated nuclear structure\"\n",
    " \n",
    "### Morphometrics\n",
    " - Trace the outline of the object (or sub-structures)\n",
    " - Can calculate the area by using equal-weight-paper \n",
    " - Employing the \"[cut-and-weigh](http://ion.chem.usu.edu/~sbialkow/Classes/361/GC/GC.html)\" method\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Segmentation Approaches\n",
    "\n",
    "\n",
    "They match up well to the world view / perspective \n",
    "\n",
    "![Approaches](../common/figures/approaches.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Segmentation approaches\n",
    "\n",
    "<table>\n",
    "<tr><th>\n",
    "Model-Based        \n",
    "</th>\n",
    "<th>\n",
    "Machine Learning Approach  \n",
    "</th></tr>\n",
    "<tr><td>    \n",
    "Experimentalist   \n",
    "</td>\n",
    "<td>\n",
    "Computer Vision / Deep Learning    \n",
    "</td></tr>    \n",
    "<tr><td valign=\"top\">\n",
    "    \n",
    "Problem-driven\n",
    " - Top-down\n",
    " - _Reality_ Model-based    \n",
    "\n",
    "</td><td valign=\"top\">\n",
    "Results-driven    \n",
    "</td></tr>    \n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Model-based Analysis\n",
    "\n",
    "![Traditional Imaging](../common/figures/image-formation.png)\n",
    "\n",
    "- Many different imaging modalities <br/>( $\\mu \\textrm{CT}$ to MRI to Confocal to Light-field to AFM). \n",
    "- Similarities in underlying equations\n",
    " - different coefficients, units, and mechanism\n",
    "\n",
    "$$ I_{measured}(\\vec{x}) = F_{system}(I_{stimulus}(\\vec{x}),S_{sample}(\\vec{x})) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Direct Imaging (simple)\n",
    "\n",
    "In many setups there is un-even illumination caused by incorrectly adjusted equipment and fluctations in power and setups\n",
    "\n",
    "$$\\begin{eqnarray}\n",
    "F_{system}(a,b) &=& a*b \\\\\n",
    "I_{stimulus} &=& \\textrm{Beam}_{profile} \\\\\n",
    "S_{system} &=&\\alpha(\\vec{x}) \\\\\n",
    "\\longrightarrow \\alpha(\\vec{x})&=&\\frac{I_{measured}(\\vec{x})}{\\textrm{Beam}_{profile}(\\vec{x})}\n",
    "\\end{eqnarray}$$\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from skimage.io import imread\n",
    "from skimage.color import rgb2gray\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.morphology import disk\n",
    "from scipy.ndimage import zoom\n",
    "import numpy as np\n",
    "\n",
    "cell_img = 1-rgb2gray(imread(\"../common/figures/Average_prokaryote_cell.jpg\"))\n",
    "s_beam_img = np.pad(disk(2)/1.0, [[1,1], [1,1]], mode = 'constant', constant_values = 0.2)\n",
    "beam_img = zoom(s_beam_img, \n",
    "                [cell_img.shape[0]/7.0, cell_img.shape[1]/7.0])\n",
    "\n",
    "fig, (ax_beam, ax_img, ax_det) = plt.subplots(1, 3, figsize = (12,4))\n",
    "\n",
    "ax_beam.imshow(beam_img, \n",
    "               cmap = 'viridis')\n",
    "ax_beam.set_title('Beam Profile')\n",
    "\n",
    "ax_img.imshow(cell_img, \n",
    "              cmap = 'viridis')\n",
    "ax_img.set_title('Sample Profile')\n",
    "\n",
    "ax_det.imshow(cell_img*beam_img, \n",
    "              cmap = 'viridis')\n",
    "ax_det.set_title('Detector');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "fig, (ax_prof) = plt.subplots(1, 1, figsize = (12,4))\n",
    "\n",
    "ax_prof.plot(beam_img[beam_img.shape[0]//2], label = 'Beam Profile')\n",
    "ax_prof.plot(cell_img[beam_img.shape[0]//2], label = 'Sample Image')\n",
    "ax_prof.plot((cell_img*beam_img)[beam_img.shape[0]//2], label = 'Detector')\n",
    "ax_prof.set_ylabel('Intensity')\n",
    "ax_prof.set_xlabel('Pixel Position')\n",
    "# make an interactive plot\n",
    "import plotly.offline as py\n",
    "import plotly.tools as tls\n",
    "py.init_notebook_mode()\n",
    "py.iplot(tls.mpl_to_plotly(fig))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Inhomogeneous illumination\n",
    "- Frequently there is a fall-off of the beam away from the center (as is the case of a Gaussian beam which frequently shows up for laser systems). \n",
    "\n",
    "- This can make extracting detail away from the center \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(1,1, figsize = (8,8))\n",
    "ax1.matshow(cell_img*beam_img, \n",
    "              cmap = 'viridis');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Absorption Imaging (X-ray, Ultrasound, Optical)\n",
    "\n",
    "#### For absorption/attenuation imaging $\\rightarrow$ [Beer-Lambert Law](http://en.wikipedia.org/wiki/Attenuation_coefficient)\n",
    " $$ I_{detector} = \\underbrace{I_{source}}_{I_{stimulus}}\\underbrace{\\exp(-\\alpha d)}_{S_{sample}} $$\n",
    "\n",
    "Different components have a different $\\alpha$ based on the strength of the interaction between the light and the chemical / nuclear structure of the material\n",
    "\n",
    "$$\\begin{eqnarray}\n",
    "I_{sample}(x,y) &=& I_{source}\\exp(-\\alpha(x,y) d) \\\\\n",
    "\\\\\n",
    "\\alpha &=& f(N,Z,\\sigma,\\cdots)\n",
    "\\end{eqnarray}$$\n",
    "\n",
    "#### For segmentation this model is: \n",
    " - there are 2 (or more) distinct components that make up the image\n",
    " - these components are distinguishable by their values (or vectors, colors, tensors, ...)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "I_source = 1.0\n",
    "d = 1.0\n",
    "alpha_1 = np.random.normal(1, 0.25, size = 100)\n",
    "alpha_2 = np.random.normal(2, 0.25, size = 100)\n",
    "alpha_3 = np.random.normal(3, 0.5, size = 100)\n",
    "\n",
    "abs_df = pd.DataFrame([dict(alpha = c_x, material = c_mat) for c_vec, c_mat in zip([alpha_1, alpha_2, alpha_3], \n",
    "                       ['material 1', 'material 2', 'material 3']) for c_x in c_vec])\n",
    "abs_df['I_detector'] = I_source*np.exp(-abs_df['alpha']*d)\n",
    "\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2,2, figsize = (12, 8))\n",
    "for c_mat, c_df in abs_df.groupby('material'):\n",
    "    ax1.scatter(x = c_df['alpha'], \n",
    "                y = c_df['I_detector'], \n",
    "                label = c_mat)\n",
    "    ax3.hist(c_df['alpha'], alpha = 0.5, label = c_mat)\n",
    "    ax2.hist(c_df['I_detector'],  alpha = 0.5, label = c_mat, orientation=\"horizontal\")\n",
    "ax1.set_xlabel('$\\\\alpha(x,y)$', fontsize = 15)\n",
    "ax1.set_ylabel('$I_{detector}$', fontsize = 18)\n",
    "ax1.legend()\n",
    "ax2.legend()\n",
    "ax3.legend(loc = 0)\n",
    "\n",
    "ax4.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Example Mammography\n",
    "Mammographic imaging is an area where model-based absorption imaging is problematic. Even if we assume a constant illumination (_rarely_ the case), \n",
    "\n",
    "$$\\begin{eqnarray}\n",
    "I_{detector} &=& \\underbrace{I_{source}}_{I_{stimulus}}\\underbrace{\\exp(-\\alpha d)}_{S_{sample}} \\\\\n",
    "&\\downarrow& \\\\\n",
    "I_{detector} &=& \\exp(-\\alpha(x,y) d(x,y)) \\\\\n",
    "&\\downarrow& \\\\\n",
    "I_{detector} &=& \\exp\\left(-\\int_{0}^{l}\\alpha(x,y, z) dz\\right) \n",
    "\\end{eqnarray}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Specifically the problem is related to the inability to separate the $\\alpha$ and $d$ terms. \n",
    "\n",
    "We model a basic breast volume as a half sphere with a constant absorption factor:\n",
    "$$\\alpha(x,y,z) = 1e-2$$\n",
    "\n",
    "$\\rightarrow$ The $\\int$ then turns into a $\\Sigma$ in discrete space\n",
    "- Air\n",
    "- Breast tissue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from skimage.morphology import ball\n",
    "\n",
    "breast_mask = ball(50)[:,50:]\n",
    "\n",
    "# just for 3d rendering, don't worry about it\n",
    "import plotly.offline as py\n",
    "from plotly.figure_factory import create_trisurf\n",
    "py.init_notebook_mode()\n",
    "from skimage.measure import marching_cubes_lewiner\n",
    "vertices, simplices, _, _ = marching_cubes_lewiner(breast_mask>0)\n",
    "x,y,z = zip(*vertices) \n",
    "fig = create_trisurf(x=x,\n",
    "                        y=y, \n",
    "                        z=z, \n",
    "                        plot_edges=False,\n",
    "                        simplices=simplices,\n",
    "                        title=\"Breast Phantom\")\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "breast_alpha = 1e-2\n",
    "breast_vol = breast_alpha*breast_mask\n",
    "i_detector = np.exp(-np.sum(breast_vol,2))\n",
    "\n",
    "fig, (ax_hist, ax_breast) = plt.subplots(1, 2, figsize = (20,8))\n",
    "\n",
    "b_img_obj = ax_breast.imshow(i_detector, cmap = 'bone_r')\n",
    "plt.colorbar(b_img_obj)\n",
    "\n",
    "ax_hist.hist(i_detector.flatten())\n",
    "ax_hist.set_xlabel('$I_{detector}$')\n",
    "ax_hist.set_ylabel('Pixel Count');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "If we know that $\\alpha$ is constant we can reconstruct d from the image\n",
    "$$ d = -\\log(I_{detector})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "breast_thickness = -np.log(i_detector)/breast_alpha\n",
    "fig, (ax_hist, ax_breast) = plt.subplots(1, 2, figsize = (12,5))\n",
    "\n",
    "b_img_obj = ax_breast.imshow(breast_thickness, cmap = 'bone')\n",
    "plt.colorbar(b_img_obj)\n",
    "\n",
    "ax_hist.hist(breast_thickness.flatten())\n",
    "ax_hist.set_xlabel('Breast Thickness ($d$) [Pixels]')\n",
    "ax_hist.set_ylabel('Pixel Count');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "fig = plt.figure(figsize = (8, 4), dpi = 200)\n",
    "ax = fig.gca(projection='3d')\n",
    "# Plot the surface.\n",
    "yy, xx = np.meshgrid(np.linspace(0, 1, breast_thickness.shape[1]),\n",
    "                       np.linspace(0, 1, breast_thickness.shape[0]))\n",
    "surf = ax.plot_surface(xx, yy, breast_thickness, cmap=plt.cm.jet,\n",
    "                       linewidth=0, antialiased=False)\n",
    "ax.view_init(elev = 30, azim = 45)\n",
    "ax.set_zlabel('Breast Thickness');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## What if $\\alpha$ is not constant?\n",
    "We run into problems when the $\\alpha$ is no longer constant. \n",
    "\n",
    "- For example if we place a dark lump in the center of the breast. \n",
    "\n",
    "- It is __impossible__ to tell if the breast is _thicker_ or if the lump inside is _denser_. \n",
    "\n",
    "For the lump below we can see on the individual slices of the sample that the lesion appears quite clearly and is very strangely shaped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "breast_vol = breast_alpha*breast_mask\n",
    "renorm_slice = np.sum(breast_mask[10:40, 0:25], 2)/np.sum(breast_mask[30, 10])\n",
    "breast_vol[10:40, 0:25] /= np.stack([renorm_slice]*breast_vol.shape[2],-1)\n",
    "\n",
    "from skimage.util import montage as montage2d\n",
    "fig, ax1 = plt.subplots(1,1, figsize = (12, 12))\n",
    "ax1.imshow(montage2d(breast_vol.swapaxes(0,2).swapaxes(1,2)[::3]), \n",
    "           cmap = 'bone', vmin = breast_alpha*.8, vmax = breast_alpha*1.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "When we make the projection and apply Beer's Law we see that it appears as a relatively constant region in the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "i_detector = np.exp(-np.sum(breast_vol,2))\n",
    "\n",
    "fig, (ax_hist, ax_breast) = plt.subplots(1, 2, figsize = (20,8))\n",
    "\n",
    "b_img_obj = ax_breast.imshow(i_detector, cmap = 'bone_r')\n",
    "plt.colorbar(b_img_obj)\n",
    "\n",
    "ax_hist.hist(i_detector.flatten())\n",
    "ax_hist.set_xlabel('$I_{detector}$')\n",
    "ax_hist.set_ylabel('Pixel Count');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## It appears as a flat constant region in the thickness reconstruction. \n",
    "\n",
    "So we fundamentally from this single image cannot answer:\n",
    "- is the breast oddly shaped?\n",
    "- or does it have an possible tumor inside of it?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "breast_thickness = -np.log(i_detector)/1e-2\n",
    "fig, (ax_hist, ax_breast) = plt.subplots(1, 2, figsize = (12,5))\n",
    "\n",
    "b_img_obj = ax_breast.imshow(breast_thickness, cmap = 'bone')\n",
    "plt.colorbar(b_img_obj)\n",
    "\n",
    "ax_hist.hist(breast_thickness.flatten())\n",
    "ax_hist.set_xlabel('Breast Thickness ($d$)\\nIn Pixels')\n",
    "ax_hist.set_ylabel('Pixel Count');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "fig = plt.figure(figsize = (8, 4), dpi = 200)\n",
    "ax = fig.gca(projection='3d')\n",
    "# Plot the surface.\n",
    "yy, xx = np.meshgrid(np.linspace(0, 1, breast_thickness.shape[1]),\n",
    "                       np.linspace(0, 1, breast_thickness.shape[0]))\n",
    "surf = ax.plot_surface(xx, yy, breast_thickness, cmap=plt.cm.jet,\n",
    "                       linewidth=0, antialiased=False)\n",
    "ax.view_init(elev = 30, azim = 130)\n",
    "ax.set_zlabel('Breast Thickness');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Where does segmentation get us?\n",
    "\n",
    "\n",
    "We convert a decimal value or something even more complicated like \n",
    "- 3 values for RGB images,\n",
    "- a spectrum for hyperspectral imaging, \n",
    "- or a vector / tensor in a mechanical stress field\n",
    "\n",
    "To a single, discrete value: \n",
    "- usually true or false, \n",
    "- but for images with phases it would be each phase, e.g. bone, air, cellular tissue.\n",
    "\n",
    "__2560 x 2560 x 2160 x 32 bit = 56GB / sample__ $\\rightarrow$ 2560 x 2560 x 2160 x **1 bit** = 1.75GB / sample\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Basic segmentation: Applying a threshold to an image\n",
    "Start out with a simple image of a cross with added noise\n",
    "$$ I(x,y) = f(x,y) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "nx = 5\n",
    "ny = 5\n",
    "xx, yy = np.meshgrid(np.arange(-nx, nx+1)/nx*2*np.pi, \n",
    "                      np.arange(-ny, ny+1)/ny*2*np.pi)\n",
    "cross_im = 1.5*np.abs(np.cos(xx*yy))/(np.abs(xx*yy)+(3*np.pi/nx))+np.random.uniform(-0.25, 0.25, size = xx.shape)\n",
    "plt.matshow(cross_im, cmap = 'hot')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The intensity can be described with a probability density function \n",
    "$$ P_f(x,y) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(1,1)\n",
    "ax1.hist(cross_im.ravel(), 20)\n",
    "ax1.set_title('$P_f(x,y)$') \n",
    "ax1.set_xlabel('Intensity')\n",
    "ax1.set_ylabel('Pixel Count');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Applying a threshold to an image\n",
    "\n",
    "By examining the image and probability distribution function, we can _deduce_ that the underyling model is a whitish phase that makes up the cross and the darkish background\n",
    "\n",
    "Applying the threshold is a deceptively simple operation\n",
    "\n",
    "$$ I(x,y) = \n",
    "\\begin{cases}\n",
    "1, & f(x,y)\\geq0.40 \\\\\n",
    "0, & f(x,y)<0.40\n",
    "\\end{cases}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "threshold = 0.4\n",
    "fig, ax1 = plt.subplots(1,1)\n",
    "ax1.imshow(cross_im, cmap = 'hot', extent = [xx.min(), xx.max(), yy.min(), yy.max()])\n",
    "thresh_img = cross_im > threshold\n",
    "\n",
    "ax1.plot(xx[np.where(thresh_img)], \n",
    "        yy[np.where(thresh_img)],\n",
    "         'ks',\n",
    "           markerfacecolor = 'green',\n",
    "           alpha = 0.5,\n",
    "         label = 'threshold',\n",
    "         markersize = 20\n",
    "           )\n",
    "ax1.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Various Thresholds\n",
    "We can see the effect of choosing various thresholds \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "fig, m_axs = plt.subplots(2,3, \n",
    "                          figsize = (15, 8))\n",
    "for c_thresh, ax1 in zip(np.linspace(0.1, 0.9, 6), m_axs.flatten()):\n",
    "    \n",
    "    ax1.imshow(cross_im,\n",
    "               cmap = 'bone', \n",
    "               extent = [xx.min(), xx.max(), yy.min(), yy.max()])\n",
    "    thresh_img = cross_im > c_thresh\n",
    "\n",
    "    ax1.plot(xx[np.where(thresh_img)], yy[np.where(thresh_img)], 'rs', alpha = 0.5, label = 'img>%2.2f' % c_thresh, markersize = 20)\n",
    "    ax1.legend(loc = 1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Segmenting Cells\n",
    "\n",
    "- We can peform the same sort of analysis with this image of cells\n",
    "- This time we can derive the model from the basic physics of the system\n",
    " - The field is illuminated by white light of nearly uniform brightness\n",
    " - Cells absorb light causing darker regions to appear in the image\n",
    " - _Lighter_ regions have no cells\n",
    " - __Darker__ regions have cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from skimage.io import imread\n",
    "from skimage.color import rgb2gray\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "cell_img = rgb2gray(imread(\"../common/figures/Cell_Colony.jpg\"))\n",
    "fig, (ax_hist, ax_img) = plt.subplots(1, 2, figsize = (15,6))\n",
    "ax_hist.hist(cell_img.ravel(), np.arange(255))\n",
    "ax_obj = ax_img.matshow(cell_img, cmap = 'bone')\n",
    "plt.colorbar(ax_obj);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from skimage.color import label2rgb\n",
    "fig, m_axs = plt.subplots(2,3, \n",
    "                          figsize = (15, 8), dpi = 200)\n",
    "for c_thresh, ax1 in zip(np.linspace(100, 200, 6), \n",
    "                         m_axs.flatten()):\n",
    "    thresh_img = cell_img < c_thresh\n",
    "\n",
    "    ax1.imshow(label2rgb(thresh_img, image = 1-cell_img, bg_label = 0, alpha = 0.4))\n",
    "    \n",
    "    ax1.set_title('img<%2.2f' % c_thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Other Image Types\n",
    "\n",
    "While scalar images are easiest, it is possible for any type of image\n",
    "$$ I(x,y) = \\vec{f}(x,y) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "nx = 10\n",
    "ny = 10\n",
    "xx, yy = np.meshgrid(np.linspace(-2*np.pi, 2*np.pi, nx), \n",
    "                      np.linspace(-2*np.pi, 2*np.pi, ny))\n",
    "\n",
    "intensity_img = 1.5*np.abs(np.cos(xx*yy))/(np.abs(xx*yy)+(3*np.pi/nx))+np.random.uniform(-0.25, 0.25, size = xx.shape)\n",
    "\n",
    "base_df = pd.DataFrame(dict(x = xx.ravel(), \n",
    "                            y = yy.ravel(), \n",
    "                            I_detector = intensity_img.ravel()))\n",
    "\n",
    "base_df['x_vec'] = base_df.apply(lambda c_row: c_row['x']/np.sqrt(1e-2+np.square(c_row['x'])+np.square(c_row['y'])), 1)\n",
    "base_df['y_vec'] = base_df.apply(lambda c_row: c_row['y']/np.sqrt(1e-2+np.square(c_row['x'])+np.square(c_row['y'])), 1)\n",
    "\n",
    "base_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.pairplot(base_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(1,1, figsize = (8, 8))\n",
    "ax1.quiver(base_df['x'], base_df['y'], base_df['x_vec'], base_df['y_vec'], base_df['I_detector'], cmap = 'hot');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Applying a threshold\n",
    "\n",
    "A threshold is now more difficult to apply since there are now two distinct variables to deal with. The standard approach can be applied to both\n",
    "$$ I(x,y) = \n",
    "\\begin{cases}\n",
    "1, & \\vec{f}_x(x,y) \\geq0.25 \\text{ and}\\\\\n",
    "& \\vec{f}_y(x,y) \\geq0.25 \\\\\n",
    "0, & \\text{otherwise}\n",
    "\\end{cases}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "thresh_df = base_df.copy()\n",
    "thresh_df['thresh'] = thresh_df.apply(lambda c_row: c_row['x_vec']>0.25 and c_row['y_vec']>0.25, 1)\n",
    "\n",
    "fig, ax1 = plt.subplots(1,1, figsize = (8, 8))\n",
    "ax1.quiver(thresh_df['x'], thresh_df['y'], thresh_df['x_vec'], thresh_df['y_vec'], thresh_df['thresh'], cmap = 'hot');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "This can also be shown on the joint probability distribution as "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(1,1, figsize = (4, 4), dpi = 200)\n",
    "ax1.hist2d(thresh_df['x_vec'], thresh_df['y_vec'], cmap = 'viridis');\n",
    "ax1.set_xlabel('$\\\\vec{f}_x(x,y)$')\n",
    "ax1.set_ylabel('$\\\\vec{f}_y(x,y)$');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Applying a threshold\n",
    "Given the presence of two variables; however, more advanced approaches can also be investigated. For example we can keep only components parallel to the x axis by using the dot product.\n",
    "$$ I(x,y) = \n",
    "\\begin{cases}\n",
    "1, & |\\vec{f}(x,y)\\cdot \\vec{i}| = 1 \\\\\n",
    "0, & \\text{otherwise}\n",
    "\\end{cases}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Looking at Orientations\n",
    "We can tune the angular acceptance by using the fact $$\\vec{x}\\cdot\\vec{y}=|\\vec{x}| |\\vec{y}| \\cos(\\theta_{x\\rightarrow y}) $$\n",
    "$$ I(x,y) = \n",
    "\\begin{cases}\n",
    "1, & \\cos^{-1}(\\vec{f}(x,y)\\cdot \\vec{i}) \\leq \\theta^{\\circ} \\\\\n",
    "0, & \\text{otherwise}\n",
    "\\end{cases}$$"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "livereveal": {
   "autolaunch": true,
   "enable_chalkboard": true,
   "footer": "March 12, 2020 - ETH 227-0966-00L: Quantitative Big Imaging/Basic Segmentation part 1",
   "header": "<table width='100%' style='margin: 0px;'><tr><td align='left'><img src='../common/figures/eth_logo_kurz_pos.svg' style='height:30px;'></td><td align='right'><img src='../common/figures/PSI-Logo.svg' style='height:50px;'></td></tr></table>",
   "scroll": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
