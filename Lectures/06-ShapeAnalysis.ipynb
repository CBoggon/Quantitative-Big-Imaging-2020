{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# ETHZ: 227-0966-00L\n",
    "# Quantitative Big Imaging\n",
    "# March 28, 2019\n",
    "\n",
    "## Shape Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "format": "row",
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (8, 8)\n",
    "plt.rcParams[\"figure.dpi\"] = 150\n",
    "plt.rcParams[\"font.size\"] = 14\n",
    "plt.rcParams['font.family'] = ['sans-serif']\n",
    "plt.rcParams['font.sans-serif'] = ['DejaVu Sans']\n",
    "plt.style.use('ggplot')\n",
    "sns.set_style(\"whitegrid\", {'axes.grid': False})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Literature / Useful References\n",
    "\n",
    "- Jean Claude, Morphometry with R\n",
    "    - [Online](http://link.springer.com/book/10.1007%2F978-0-387-77789-4) through ETHZ\n",
    "    - [Buy it](http://www.amazon.com/Morphometrics-R-Use-Julien-Claude/dp/038777789X)\n",
    "- John C. Russ, “The Image Processing Handbook”,(Boca Raton, CRC Press)\n",
    "    - Available [online](http://dx.doi.org/10.1201/9780203881095) within domain ethz.ch (or proxy.ethz.ch / public VPN) \n",
    "- Principal Component Analysis\n",
    "    - Venables, W. N. and B. D. Ripley (2002). Modern Applied Statistics with S, Springer-Verlag\n",
    "- Shape Tensors\n",
    "    - http://www.cs.utah.edu/~gk/papers/vissym04/\n",
    "    - Doube, M.,et al. (2010). BoneJ: Free and extensible bone image analysis in ImageJ. Bone, 47, 1076–9. doi:10.1016/j.bone.2010.08.023\n",
    "    - Mader, K. , et al. (2013). A quantitative framework for the 3D characterization of the osteocyte lacunar system. Bone, 57(1), 142–154. doi:10.1016/j.bone.2013.06.026\n",
    " \n",
    "    - Wilhelm Burger, Mark Burge. Principles of Digital Image Processing: Core Algorithms. Springer-Verlag, London, 2009.\n",
    "    -  B. Jähne. Digital Image Processing. Springer-Verlag,\n",
    "           Berlin-Heidelberg, 6. edition, 2005.\n",
    "    -  T. H. Reiss. Recognizing Planar Objects Using Invariant Image\n",
    "           Features, from Lecture notes in computer science, p. 676. Springer,\n",
    "           Berlin, 1993.\n",
    "    - http://en.wikipedia.org/wiki/Image_moment\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Previously on QBI ...\n",
    "\n",
    "<table>\n",
    "    <tr><th>Image Enhancment</th><th>Segmentation</th><th>Automatic Methods</th></tr>\n",
    "    <tr>\n",
    "    <td>\n",
    "        \n",
    "- Highlighting the contrast of interest in images\n",
    "- Minimizing Noise\n",
    "\n",
    "    </td>\n",
    "    <td>\n",
    "    \n",
    "- Understanding value histograms\n",
    "- Dealing with multi-valued data\n",
    "    \n",
    "    </td>\n",
    "    <td>\n",
    "    \n",
    "- Hysteresis Method\n",
    "- K-Means Analysis\n",
    "\n",
    "    </td>    \n",
    "    </tr>\n",
    "    <tr><th>Regions of Interest</th><th>Machine Learning</th><th></th></tr>\n",
    "    <tr><td>\n",
    "    \n",
    "- Contouring\n",
    "\n",
    "    </td><td></td></tr>\n",
    "    </table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Learning Objectives\n",
    "\n",
    "## Motivation (Why and How?)\n",
    "- How do we quantify where and __how big__ our objects are?\n",
    "- How can we say something about the __shape__?\n",
    "- How can we compare objects of __different sizes__?\n",
    "- How can we __compare two images__ on the basis of the shape as calculated from the images?\n",
    "- How can we put objects into an \n",
    "    - finite element simulation? \n",
    "    - or make pretty renderings?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Outline\n",
    "\n",
    "- Motivation (Why and How?)\n",
    "- Object Characterization\n",
    "- Volume\n",
    "- Center and Extents\n",
    "- Anisotropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Metrics\n",
    "\n",
    "- Shape Tensor\n",
    "- Principal Component Analysis\n",
    "- Ellipsoid Representation\n",
    "- Scale-free metrics\n",
    "- Anisotropy, Oblateness\n",
    "- Meshing\n",
    " - Marching Cubes\n",
    " - Isosurfaces\n",
    "- Surface Area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Motivation\n",
    "\n",
    "\n",
    "We have dramatically simplified our data, but there is still too much.\n",
    "\n",
    "- We perform an experiment bone to see how big the cells are inside the tissue\n",
    "$$\\downarrow$$ ![Bone Measurement](ext-figures/tomoimage.png) \n",
    "\n",
    "### 2560 x 2560 x 2160 x 32 bit\n",
    "_56GB / sample_\n",
    "- Filtering and Enhancement!  \n",
    "$$\\downarrow$$\n",
    "- 56GB of less noisy data\n",
    "\n",
    "***\n",
    "\n",
    "- __Segmentation__\n",
    "\n",
    "$$\\downarrow$$\n",
    "\n",
    "### 2560 x 2560 x 2160 x 1 bit\n",
    "(1.75GB / sample)\n",
    "\n",
    "- Still an aweful lot of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# What did we want in the first place?\n",
    "\n",
    "### _Single number_ :\n",
    "* volume fraction,\n",
    "* cell count,\n",
    "* average cell stretch,\n",
    "* cell volume variability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Component labelling\n",
    "\n",
    "### Segmentation\n",
    "- Segmentation identified pixels belonging to some class\n",
    "    - a single set containing all pixels!\n",
    "    \n",
    "### To measure objects in an image, they need to be uniquely identified.\n",
    "- Basic component labelling\n",
    "    - give the same label to all pixels touching each other.\n",
    "    - has its drawbacks... touching item are treated as one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "# Component Labeling\n",
    "\n",
    "Once we have a clearly segmented image, it is often helpful to identify the sub-components of this image. The easist method for identifying these subcomponents is called component labeling which again uses the neighborhood $\\mathcal{N}$ as a criterion for connectivity, resulting in pixels which are touching being part of the same object.\n",
    "\n",
    "\n",
    "In general, the approach works well since usually when different regions are touching, they are related. It runs into issues when you have multiple regions which agglomerate together, for example a continuous pore network (1 object) or a cluster of touching cells.\n",
    "\n",
    "Here we show some examples from Cityscape Data taken in Aachen (https://www.cityscapes-dataset.com/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "format": "tab",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from skimage.io import imread\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "car_img = imread('ext-figures/aachen_img.png')\n",
    "seg_img = imread('ext-figures/aachen_label.png')[::4, ::4] == 26\n",
    "print('image dimensions', car_img.shape, seg_img.shape)\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))\n",
    "ax1.imshow(car_img)\n",
    "ax1.set_title('Input Image')\n",
    "\n",
    "ax2.imshow(seg_img, cmap='bone')\n",
    "ax2.set_title('Segmented Image')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The more general formulation of the problem is for networks (roads, computers, social). Are the points start and finish connected?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "format": "tab",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from skimage.morphology import label\n",
    "help(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "format": "tab",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))\n",
    "ax1.imshow(seg_img, cmap='bone')\n",
    "ax1.set_title('Segmented Image')\n",
    "lab_img = label(seg_img)\n",
    "ax2.imshow(lab_img, cmap=plt.cm.gist_earth)\n",
    "ax2.set_title('Labeled Image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "format": "column",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "fig, (ax3) = plt.subplots(1, 1)\n",
    "ax3.hist(lab_img.ravel())\n",
    "ax3.set_title('Label Counts')\n",
    "ax3.set_yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Component Labeling: Algorithm\n",
    "\n",
    "We start off with all of the pixels in either foreground (1) or background (0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "format": "column",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from skimage.morphology import label\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "seg_img = np.eye(9, dtype=int)\n",
    "seg_img[4, 4] = 0\n",
    "seg_img += seg_img[::-1]\n",
    "sns.heatmap(seg_img, annot=True, fmt=\"d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Give each point in the image a unique label\n",
    "- For each point $(x,y)\\in\\text{Foreground}$\n",
    " - Set value to $I_{x,y} = x+y*width+1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "format": "column",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "idx_img = np.zeros_like(seg_img)\n",
    "for x in range(seg_img.shape[0]):\n",
    "    for y in range(seg_img.shape[1]):\n",
    "        if seg_img[x, y] > 0:\n",
    "            idx_img[x, y] = x+y*seg_img.shape[0]+1\n",
    "sns.heatmap(idx_img, annot=True,\n",
    "            fmt=\"d\", cmap='nipy_spectral')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In a [brushfire](http://www.sciencedirect.com/science/article/pii/S0921889007000966)-style algorithm\n",
    "- For each point $(x,y)\\in\\text{Foreground}$\n",
    "    - For each point $(x^{\\prime},y^{\\prime})\\in\\mathcal{N}(x,y)$\n",
    "    - if $(x^{\\prime},y^{\\prime})\\in\\text{Foreground}$\n",
    "        - Set the label to $\\min(I_{x,y}, I_{x^{\\prime},y^{\\prime}})$\n",
    "- Repeat until no more labels have been changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "format": "tab",
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "fig, m_axs = plt.subplots(2, 2, figsize=(15, 10))\n",
    "last_img = idx_img.copy()\n",
    "img_list = [last_img]\n",
    "for iteration, c_ax in enumerate(m_axs.flatten(), 1):\n",
    "    cur_img = last_img.copy()\n",
    "\n",
    "    for x in range(last_img.shape[0]):\n",
    "        for y in range(last_img.shape[1]):\n",
    "            if last_img[x, y] > 0:\n",
    "                i_xy = last_img[x, y]\n",
    "                for xp in [-1, 0, 1]:\n",
    "                    if (x+xp < last_img.shape[0]) and (x+xp >= 0):\n",
    "                        for yp in [-1, 0, 1]:\n",
    "                            if (y+yp < last_img.shape[1]) and (y+yp >= 0):\n",
    "                                i_xpyp = last_img[x+xp, y+yp]\n",
    "                                if i_xpyp > 0:\n",
    "\n",
    "                                    new_val = min(i_xy, i_xpyp, cur_img[x, y])\n",
    "                                    if cur_img[x, y] != new_val:\n",
    "                                        print((x, y), i_xy, 'vs', (x+xp,\n",
    "                                                                   y+yp), i_xpyp, '->', new_val)\n",
    "                                        cur_img[x, y] = new_val\n",
    "\n",
    "    img_list += [cur_img]\n",
    "    sns.heatmap(cur_img,\n",
    "                annot=True,\n",
    "                fmt=\"d\",\n",
    "                cmap='nipy_spectral',\n",
    "                ax=c_ax)\n",
    "    c_ax.set_title('Iteration #{}'.format(iteration))\n",
    "    if (cur_img == last_img).all():\n",
    "        print('Done')\n",
    "        break\n",
    "    else:\n",
    "        print('Iteration', iteration,\n",
    "              'Groups', len(np.unique(cur_img[cur_img > 0].ravel())),\n",
    "              'Changes', np.sum(cur_img != last_img))\n",
    "        last_img = cur_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The image very quickly converges and after 4 iterations the task is complete. \n",
    "\n",
    "- For larger more complicated images with thousands of components this task can take longer, \n",
    "- There exist much more efficient [algorithms](https://www.cs.princeton.edu/~rs/AlgsDS07/01UnionFind.pdf) for labeling components which alleviate this issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "format": "tab",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib.animation import FuncAnimation\n",
    "from IPython.display import HTML\n",
    "fig, c_ax = plt.subplots(1, 1, figsize=(5, 5), dpi=100)\n",
    "\n",
    "\n",
    "def update_frame(i):\n",
    "    plt.cla()\n",
    "    sns.heatmap(img_list[i],\n",
    "                annot=True,\n",
    "                fmt=\"d\",\n",
    "                cmap='nipy_spectral',\n",
    "                ax=c_ax,\n",
    "                cbar=False,\n",
    "                vmin=img_list[0].min(),\n",
    "                vmax=img_list[0].max())\n",
    "    c_ax.set_title('Iteration #{}, Groups {}'.format(i+1,\n",
    "                                                     len(np.unique(img_list[i][img_list[i] > 0].ravel()))))\n",
    "# write animation frames\n",
    "anim_code = FuncAnimation(fig, update_frame, frames=len(img_list)-1,\n",
    "                          interval=1000, repeat_delay=2000).to_html5_video()\n",
    "plt.close('all')\n",
    "HTML(anim_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Bigger Images\n",
    "How does the same algorithm apply to bigger images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "format": "tab",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from skimage.io import imread\n",
    "from skimage.morphology import label\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "seg_img = (imread('ext-figures/aachen_label.png')[::4, ::4] == 26)[110:130:2, 370:420:3]\n",
    "seg_img[9, 1] = 1\n",
    "_, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 7), dpi=150)\n",
    "sns.heatmap(seg_img, annot=True, fmt=\"d\", ax=ax1,\n",
    "            cmap='nipy_spectral', cbar=False)\n",
    "ax1.set_title('Binary image')\n",
    "\n",
    "idx_img = seg_img * np.arange(len(seg_img.ravel())).reshape(seg_img.shape)\n",
    "sns.heatmap(idx_img, annot=True, fmt=\"d\", ax=ax2,\n",
    "            cmap='nipy_spectral', cbar=False)\n",
    "ax2.set_title('Initial labels');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Run the labelling on the car image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "format": "column",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "last_img = idx_img.copy()\n",
    "img_list = [last_img]\n",
    "for iteration in range(99):\n",
    "    cur_img = last_img.copy()\n",
    "    for x in range(last_img.shape[0]):\n",
    "        for y in range(last_img.shape[1]):\n",
    "            if last_img[x, y] > 0:\n",
    "                i_xy = last_img[x, y]\n",
    "                for xp in [-1, 0, 1]:\n",
    "                    if (x+xp < last_img.shape[0]) and (x+xp >= 0):\n",
    "                        for yp in [-1, 0, 1]:\n",
    "                            if (y+yp < last_img.shape[1]) and (y+yp >= 0):\n",
    "                                i_xpyp = last_img[x+xp, y+yp]\n",
    "                                if i_xpyp > 0:\n",
    "                                    new_val = min(i_xy, i_xpyp, cur_img[x, y])\n",
    "                                    if cur_img[x, y] != new_val:\n",
    "                                        cur_img[x, y] = new_val\n",
    "\n",
    "    img_list += [cur_img] # stores the current image in the iteration list\n",
    "    if (cur_img == last_img).all():\n",
    "        print('Done')\n",
    "        break\n",
    "    else:\n",
    "        print('Iteration', iteration,\n",
    "              'Groups', len(np.unique(cur_img[cur_img > 0].ravel())),\n",
    "              'Changes', np.sum(cur_img != last_img))\n",
    "        last_img = cur_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "format": "tab",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib.animation import FuncAnimation\n",
    "from IPython.display import HTML\n",
    "fig, c_ax = plt.subplots(1, 1, figsize=(5, 5), dpi=150)\n",
    "\n",
    "def update_frame(i):\n",
    "    plt.cla()\n",
    "    sns.heatmap(img_list[i],\n",
    "                annot=True,\n",
    "                fmt=\"d\",\n",
    "                cmap='nipy_spectral',\n",
    "                ax=c_ax,\n",
    "                cbar=False,\n",
    "                vmin=img_list[0].min(),\n",
    "                vmax=img_list[0].max())\n",
    "    c_ax.set_title('Iteration #{}, Groups {}'.format(i+1,\n",
    "                                                     len(np.unique(img_list[i][img_list[i] > 0].ravel()))))\n",
    "\n",
    "\n",
    "# write animation frames\n",
    "anim_code = FuncAnimation(fig,\n",
    "                          update_frame,\n",
    "                          frames=len(img_list)-1,\n",
    "                          interval=500,\n",
    "                          repeat_delay=1000).to_html5_video()\n",
    "plt.close('all')\n",
    "HTML(anim_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Different Neighborhoods\n",
    "We can expand beyond the 3x3 neighborhood to a 5x5 for example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "format": "tab",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "last_img = idx_img.copy()\n",
    "img_list = [last_img]\n",
    "for iteration in range(99):\n",
    "    cur_img = last_img.copy()\n",
    "    for x in range(last_img.shape[0]):\n",
    "        for y in range(last_img.shape[1]):\n",
    "            if last_img[x, y] > 0:\n",
    "                i_xy = last_img[x, y]\n",
    "                for xp in [-2, -1, 0, 1, 2]:\n",
    "                    if (x+xp < last_img.shape[0]) and (x+xp >= 0):\n",
    "                        for yp in [-2, -1, 0, 1, 2]:\n",
    "                            if (y+yp < last_img.shape[1]) and (y+yp >= 0):\n",
    "                                i_xpyp = last_img[x+xp, y+yp]\n",
    "                                if i_xpyp > 0:\n",
    "                                    new_val = min(i_xy, i_xpyp, cur_img[x, y])\n",
    "                                    if cur_img[x, y] != new_val:\n",
    "                                        cur_img[x, y] = new_val\n",
    "\n",
    "    img_list += [cur_img]\n",
    "    if (cur_img == last_img).all():\n",
    "        print('Done')\n",
    "        break\n",
    "    else:\n",
    "        print('Iteration', iteration,\n",
    "              'Groups', len(np.unique(cur_img[cur_img > 0].ravel())),\n",
    "              'Changes', np.sum(cur_img != last_img))\n",
    "        last_img = cur_img\n",
    "\n",
    "fig, c_ax = plt.subplots(1, 1, figsize=(5, 5), dpi=100)\n",
    "\n",
    "\n",
    "def update_frame(i):\n",
    "    plt.cla()\n",
    "    sns.heatmap(img_list[i],\n",
    "                annot=True,\n",
    "                fmt=\"d\",\n",
    "                cmap='nipy_spectral',\n",
    "                ax=c_ax,\n",
    "                cbar=False,\n",
    "                vmin=img_list[0].min(),\n",
    "                vmax=img_list[0].max())\n",
    "    c_ax.set_title('Iteration #{}, Groups {}'.format(i+1,\n",
    "                                                     len(np.unique(img_list[i][img_list[i] > 0].ravel()))))\n",
    "\n",
    "\n",
    "# write animation frames\n",
    "anim_code = FuncAnimation(fig,\n",
    "                          update_frame,\n",
    "                          frames=len(img_list)-1,\n",
    "                          interval=500,\n",
    "                          repeat_delay=1000).to_html5_video()\n",
    "plt.close('all')\n",
    "HTML(anim_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Or a smaller kernel\n",
    "By using a smaller kernel (in this case where $\\sqrt{x^2+y^2}<=1$, we cause the number of iterations to fill to increase and prevent the last pixel from being grouped since it is only connected diagonally\n",
    "\n",
    "|   |   |   |\n",
    "|--:|--:|--:|\n",
    "|  0|  1|  0|\n",
    "|  1|  1|  1|\n",
    "|  0|  1|  0|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "format": "tab",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "last_img = idx_img.copy()\n",
    "img_list = [last_img]\n",
    "for iteration in range(99):\n",
    "    cur_img = last_img.copy()\n",
    "    for x in range(last_img.shape[0]):\n",
    "        for y in range(last_img.shape[1]):\n",
    "            if last_img[x, y] > 0:\n",
    "                i_xy = last_img[x, y]\n",
    "                for xp in [-1, 0, 1]:\n",
    "                    if (x+xp < last_img.shape[0]) and (x+xp >= 0):\n",
    "                        for yp in [-1, 0, 1]:\n",
    "                            if np.abs(xp)+np.abs(yp) <= 1:\n",
    "                                if (y+yp < last_img.shape[1]) and (y+yp >= 0):\n",
    "                                    i_xpyp = last_img[x+xp, y+yp]\n",
    "                                    if i_xpyp > 0:\n",
    "                                        new_val = min(\n",
    "                                            i_xy, i_xpyp, cur_img[x, y])\n",
    "                                        if cur_img[x, y] != new_val:\n",
    "                                            cur_img[x, y] = new_val\n",
    "\n",
    "    img_list += [cur_img]\n",
    "    if (cur_img == last_img).all():\n",
    "        print('Done')\n",
    "        break\n",
    "    else:\n",
    "        print('Iteration', iteration,\n",
    "              'Groups', len(np.unique(cur_img[cur_img > 0].ravel())),\n",
    "              'Changes', np.sum(cur_img != last_img))\n",
    "        last_img = cur_img\n",
    "\n",
    "fig, c_ax = plt.subplots(1, 1, figsize=(6, 6), dpi=100)\n",
    "\n",
    "\n",
    "def update_frame(i):\n",
    "    plt.cla()\n",
    "    sns.heatmap(img_list[i],\n",
    "                annot=True,\n",
    "                fmt=\"d\",\n",
    "                cmap='nipy_spectral',\n",
    "                ax=c_ax,\n",
    "                cbar=False,\n",
    "                vmin=img_list[0].min(),\n",
    "                vmax=img_list[0].max())\n",
    "    c_ax.set_title('Iteration #{}, Groups {}'.format(i+1,\n",
    "                                                     len(np.unique(img_list[i][img_list[i] > 0].ravel()))))\n",
    "\n",
    "\n",
    "# write animation frames\n",
    "anim_code = FuncAnimation(fig,\n",
    "                          update_frame,\n",
    "                          frames=len(img_list)-1,\n",
    "                          interval=500,\n",
    "                          repeat_delay=1000).to_html5_video()\n",
    "plt.close('all')\n",
    "HTML(anim_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Comparing different neighborhoods\n",
    "\n",
    "|Neighborhood size|Iterations| Segments |\n",
    "|----------------:|---------:|---------:|\n",
    "|      3x3        |    9     |    2     |\n",
    "|      5x5        |    5     |    1     |\n",
    "|      cross      |    14    |    3     |     \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Component Labeling: Beyond\n",
    "\n",
    "\n",
    "Now all the voxels which are connected have the same label. We can then perform simple metrics like\n",
    "\n",
    "- counting the number of voxels in each label to estimate volume.\n",
    "- looking at the change in volume during erosion or dilation to estimate surface area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What we would like to to do\n",
    "\n",
    "- Count the cells\n",
    "- Say something about the cells\n",
    "- Compare the cells in this image to another image\n",
    "\n",
    "\n",
    "... But where do we start?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Object position - Center of Volume (COV): With a single object\n",
    "\n",
    "$$ I_{id}(x,y) = \n",
    "\\begin{cases}\n",
    "1, & L(x,y) = id \\\\\n",
    "0, & \\text{otherwise}\n",
    "\\end{cases}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "format": "tab",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "from skimage.io import imread\n",
    "from skimage.morphology import label\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "seg_img = imread('ext-figures/aachen_label.png') == 26\n",
    "seg_img = seg_img[::4, ::4]\n",
    "seg_img = seg_img[110:130:2, 370:420:3]\n",
    "seg_img[9, 1] = 1\n",
    "lab_img = label(seg_img)\n",
    "fig, ax = plt.subplots(figsize=[8,6],dpi=100)\n",
    "# Using matshow here just because it sets the ticks up nicely. imshow is faster.\n",
    "ax.matshow(lab_img,cmap='viridis')\n",
    "\n",
    "for (i, j), z in np.ndenumerate(lab_img):\n",
    "    ax.text(j, i, '{}'.format(z), ha='center', va='center')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Define a center\n",
    "$$ \\bar{x} = \\frac{1}{N} \\sum_{\\vec{v}\\in I_{id}} \\vec{v}\\cdot\\vec{i} $$\n",
    "$$ \\bar{y} = \\frac{1}{N} \\sum_{\\vec{v}\\in I_{id}} \\vec{v}\\cdot\\vec{j} $$\n",
    "$$ \\bar{z} = \\frac{1}{N} \\sum_{\\vec{v}\\in I_{id}} \\vec{v}\\cdot\\vec{k} $$\n",
    "\n",
    "i.e. the average position of all pixels in each direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "format": "tab",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "x_coord, y_coord = [], []\n",
    "for x in range(lab_img.shape[0]):\n",
    "    for y in range(lab_img.shape[1]):\n",
    "        if lab_img[x, y] == 1:\n",
    "            x_coord += [x]\n",
    "            y_coord += [y]\n",
    "print('x,y coordinates', list(zip(x_coord, y_coord)))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=[8,6],dpi=100)\n",
    "# Using matshow here just because it sets the ticks up nicely. imshow is faster.\n",
    "ax.matshow(lab_img,cmap='viridis')\n",
    "ax.plot(np.mean(y_coord),np.mean(x_coord),'rX',\n",
    "        label=\"x={0:0.2f}, y= {1:0.2f}\".format(np.mean(x_coord), np.mean(y_coord)))\n",
    "ax.legend()\n",
    "for (i, j), z in np.ndenumerate(lab_img):\n",
    "    ax.text(j, i, '{}'.format(z), ha='center', va='center')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Center of Mass (COM): With a single object\n",
    "\n",
    "If the gray values are kept (or other meaningful ones are used), this can be seen as a weighted center of volume or center of mass (using $I_{gy}$ to distinguish it from the labels)\n",
    "\n",
    "### Define a center\n",
    "$$ \\Sigma I_{gy} = \\frac{1}{N} \\sum_{\\vec{v}\\in I_{id}} I_{gy}(\\vec{v}) $$\n",
    "$$ \\bar{x} = \\frac{1}{\\Sigma I_{gy}} \\sum_{\\vec{v}\\in I_{id}} (\\vec{v}\\cdot\\vec{i}) I_{gy}(\\vec{v}) $$\n",
    "$$ \\bar{y} = \\frac{1}{\\Sigma I_{gy}} \\sum_{\\vec{v}\\in I_{id}} (\\vec{v}\\cdot\\vec{j}) I_{gy}(\\vec{v}) $$\n",
    "$$ \\bar{z} = \\frac{1}{\\Sigma I_{gy}} \\sum_{\\vec{v}\\in I_{id}} (\\vec{v}\\cdot\\vec{k}) I_{gy}(\\vec{v}) $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "format": "row",
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "xx, yy = np.meshgrid(np.linspace(0, 10, 50),\n",
    "                     np.linspace(0, 10, 50))\n",
    "gray_img = 100*(np.abs(xx*yy-7) + np.square(yy-4))+0.25\n",
    "gray_img *= np.abs(xx-5) < 3\n",
    "gray_img *= np.abs(yy-5) < 3\n",
    "gray_img[gray_img > 0] += 5\n",
    "seg_img = (gray_img > 0).astype(int)\n",
    "_, (ax1, ax2) = plt.subplots(1, 2,\n",
    "                             figsize=(14, 6),\n",
    "                             dpi=150)\n",
    "\n",
    "sns.heatmap(gray_img,\n",
    "            ax=ax1,\n",
    "            cmap='bone_r',\n",
    "            cbar=True)\n",
    "ax1.set_title('Intensity Image')\n",
    "\n",
    "sns.heatmap(seg_img,\n",
    "            ax=ax2,\n",
    "            cmap='bone',\n",
    "            cbar=False)\n",
    "ax2.set_title('Segmented Image');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "format": "tab",
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "x_coord, y_coord, i_val = [], [], []\n",
    "for x in range(seg_img.shape[0]):\n",
    "    for y in range(seg_img.shape[1]):\n",
    "        if seg_img[x, y] == 1:\n",
    "            x_coord += [x]\n",
    "            y_coord += [y]\n",
    "            i_val += [gray_img[x, y]]\n",
    "\n",
    "x_coord = np.array(x_coord)\n",
    "y_coord = np.array(y_coord)\n",
    "i_val = np.array(i_val)\n",
    "cov_x = np.mean(x_coord)\n",
    "cov_y = np.mean(y_coord)\n",
    "\n",
    "display(Markdown(\"\"\"## Center of Volume: \n",
    "- $\\\\bar{x} = %2.2f$\n",
    "- $\\\\bar{y} = %2.2f $\"\"\" %\n",
    "                 (cov_x, cov_y)));\n",
    "\n",
    "com_x = np.sum(x_coord*i_val)/np.sum(i_val)\n",
    "com_y = np.sum(y_coord*i_val)/np.sum(i_val)\n",
    "\n",
    "display(Markdown(\"\"\"## Center of Mass: \n",
    "- $\\\\bar{x}_m = %2.2f$\n",
    "- $\\\\bar{y}_m = %2.2f $\"\"\" % (com_x, com_y)));\n",
    "\n",
    "_, (ax1) = plt.subplots(1, 1,\n",
    "                        figsize=(7, 7),\n",
    "                        dpi=150)\n",
    "\n",
    "ax1.matshow(gray_img,\n",
    "            cmap='bone_r')\n",
    "ax1.set_title('Intensity Image')\n",
    "ax1.plot([cov_y], [cov_x], 'ro',\n",
    "         label='COV', markersize=20)\n",
    "ax1.plot([com_y], [com_x], 'bo',\n",
    "         label='COM', markersize=20)\n",
    "ax1.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Further object metrics\n",
    "\n",
    "The center tells the position of an object. \n",
    "\n",
    "We want more! E.g. metrics like:\n",
    "- Area\n",
    "- Perimeter length\n",
    "- Sphericity \n",
    "- Orientation\n",
    "\n",
    "... and more\n",
    "\n",
    "```regionprops``` gives us all this!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "format": "column",
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from skimage.measure import regionprops\n",
    "help(regionprops)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Let's try regionprops on our image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "format": "tab",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from skimage.measure import regionprops\n",
    "all_regs = regionprops(seg_img, intensity_image=gray_img)\n",
    "for c_reg in all_regs:\n",
    "    display(Markdown('# Region: {}'.format(c_reg.label)))\n",
    "    for k in dir(c_reg):\n",
    "        if not k.startswith('_') and ('image' not in k):\n",
    "            display(Markdown('- {} {}'.format(k, getattr(c_reg, k))));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Extents: With a single object\n",
    "\n",
    "Exents or caliper lenghts are the size of the object in a given direction. Since the coordinates of our image our $x$ and $y$ the extents are calculated in these directions\n",
    "\n",
    "Define extents as the minimum and maximum values along the projection of the shape in each direction\n",
    "$$ \\text{Ext}_x = \\left\\{ \\forall \\vec{v}\\in I_{id}: max(\\vec{v}\\cdot\\vec{i})-min(\\vec{v}\\cdot\\vec{i})  \\right\\} $$\n",
    "$$ \\text{Ext}_y = \\left\\{ \\forall \\vec{v}\\in I_{id}: max(\\vec{v}\\cdot\\vec{j})-min(\\vec{v}\\cdot\\vec{j})  \\right\\} $$\n",
    "$$ \\text{Ext}_z = \\left\\{ \\forall \\vec{}\\in I_{id}: max(\\vec{v}\\cdot\\vec{k})-min(\\vec{v}\\cdot\\vec{k})  \\right\\} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lots of information \n",
    "We can tell a lot about each object now, but...\n",
    "- Too abstract\n",
    "- Too specific\n",
    "\n",
    "Ask biologists in the class if they ever asked \n",
    "- \"How long is a cell in the $x$ direction?\"\n",
    "- \"how about $y$?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Where is this information useful?\n",
    "\n",
    "### Let's look at a car item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "format": "tab",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "from skimage.io import imread\n",
    "from skimage.morphology import label\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "seg_img = imread('ext-figures/aachen_label.png') == 26\n",
    "seg_img = seg_img[::4, ::4]\n",
    "seg_img = seg_img[110:130:2, 378:420:3] > 0\n",
    "seg_img = np.pad(seg_img, 3, mode='constant')\n",
    "_, (ax1) = plt.subplots(1, 1,\n",
    "                        figsize=(7, 7),\n",
    "                        dpi=100)\n",
    "ax1.matshow(seg_img,\n",
    "            cmap='bone_r');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "format": "column",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "x_coord, y_coord = [], []\n",
    "for x in range(seg_img.shape[0]):\n",
    "    for y in range(seg_img.shape[1]):\n",
    "        if seg_img[x, y] == 1:\n",
    "            x_coord += [x]\n",
    "            y_coord += [y]\n",
    "xmin = np.min(x_coord)\n",
    "xmax = np.max(x_coord)\n",
    "ymin = np.min(y_coord)\n",
    "ymax = np.max(y_coord)\n",
    "print('X -> ', 'Min:', xmin,\n",
    "      'Max:', xmax)\n",
    "print('Y -> ', 'Min:', ymin,\n",
    "      'Max:', ymax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "format": "tab",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib.collections import PatchCollection\n",
    "from matplotlib.patches import Rectangle\n",
    "_, (ax1) = plt.subplots(1, 1,\n",
    "                        figsize=(7, 7),\n",
    "                        dpi=100)\n",
    "\n",
    "ax1.matshow(seg_img,\n",
    "            cmap='bone_r')\n",
    "\n",
    "xw = (xmax-xmin)\n",
    "yw = (ymax-ymin)\n",
    "\n",
    "c_bbox = [Rectangle(xy=(ymin, xmin),\n",
    "                    width=yw,\n",
    "                    height=xw\n",
    "                    )]\n",
    "c_bb_patch = PatchCollection(c_bbox,\n",
    "                             facecolor='none',\n",
    "                             edgecolor='red',\n",
    "                             linewidth=4,\n",
    "                             alpha=0.5)\n",
    "ax1.add_collection(c_bb_patch);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Concrete Example\n",
    "So how can we begin to apply the tools we have developed?\n",
    "\n",
    "We take the original car scene from before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "format": "tab",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from skimage.measure import regionprops, label\n",
    "from skimage.io import imread\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "car_img = np.clip(imread('ext-figures/aachen_img.png')\n",
    "                  [75:150]*2.0, 0, 255).astype(np.uint8)\n",
    "lab_img = label(imread('ext-figures/aachen_label.png')[::4, ::4] == 26)[75:150]\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(20, 8))\n",
    "ax1.imshow(car_img)\n",
    "ax1.set_title('Input Image');\n",
    "\n",
    "plt.colorbar(ax2.imshow(lab_img, cmap='nipy_spectral'))\n",
    "ax2.set_title('Labeled Image');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Shape Analysis\n",
    "We can perform shape analysis on the image and calculate basic shape parameters for each object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "format": "tab",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from skimage.measure import regionprops\n",
    "from matplotlib.patches import Rectangle\n",
    "from matplotlib.collections import PatchCollection\n",
    "\n",
    "# shape analysis\n",
    "all_regions = regionprops(lab_img)\n",
    "\n",
    "fig, ax1 = plt.subplots(1, 1, figsize=(12, 6), dpi=100)\n",
    "ax1.imshow(car_img)\n",
    "print('Found ', len(all_regions), 'regions')\n",
    "bbox_list = []\n",
    "for c_reg in all_regions:\n",
    "    ax1.plot(c_reg.centroid[1], c_reg.centroid[0], 'o', markersize=5)\n",
    "    bbox_list += [Rectangle(xy=(c_reg.bbox[1],\n",
    "                                c_reg.bbox[0]),\n",
    "                            width=c_reg.bbox[3]-c_reg.bbox[1],\n",
    "                            height=c_reg.bbox[2]-c_reg.bbox[0]\n",
    "                            )]\n",
    "c_bb_patch = PatchCollection(bbox_list,\n",
    "                             facecolor='none',\n",
    "                             edgecolor='red',\n",
    "                             linewidth=4,\n",
    "                             alpha=0.5)\n",
    "ax1.add_collection(c_bb_patch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Statistics\n",
    "We can then generate a table full of these basic parameters for each object. In this case, we add color as an additional description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "format": "tab",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import webcolors\n",
    "import pandas as pd\n",
    "from skimage.morphology import erosion, disk\n",
    "\n",
    "\n",
    "def ed_img(in_img):\n",
    "    # shrink an image to a few pixels\n",
    "    cur_img = in_img.copy()\n",
    "    while cur_img.max() > 0:\n",
    "        last_img = cur_img\n",
    "        cur_img = erosion(cur_img, disk(1))\n",
    "    return last_img\n",
    "\n",
    "\n",
    "# guess color name based on rgb value\n",
    "color_name_class = KNeighborsClassifier(1)\n",
    "c_names = sorted(webcolors.css3_names_to_hex.keys())\n",
    "color_name_class.fit([tuple(webcolors.name_to_rgb(k)) for k in c_names],\n",
    "                     c_names)\n",
    "\n",
    "\n",
    "reg_df = pd.DataFrame([dict(label=c_reg.label,\n",
    "                            bbox=c_reg.bbox,\n",
    "                            area=c_reg.area,\n",
    "                            centroid=c_reg.centroid,\n",
    "                            color=color_name_class.predict(np.mean(car_img[ed_img(lab_img == c_reg.label)], 0)[:3].reshape((1, -1)))[0])\n",
    "                       for c_reg in all_regions])\n",
    "fig, m_axs = plt.subplots(np.floor(len(all_regions)/3).astype(int),3, figsize=(10,10))\n",
    "for c_ax, c_reg in zip(m_axs.ravel(), all_regions):\n",
    "    c_ax.imshow(car_img[c_reg.bbox[0]:c_reg.bbox[2],\n",
    "                        c_reg.bbox[1]:c_reg.bbox[3]\n",
    "                        ])\n",
    "    c_ax.axis('off')\n",
    "    c_ax.set_title('Label {}'.format(c_reg.label))\n",
    "reg_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Object anisotropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Anisotropy: What is it?\n",
    "===\n",
    "By definition (New Oxford American): ```varying in magnitude according to the direction of measurement.```\n",
    "\n",
    "- It allows us to define metrics in respect to one another and thereby characterize shape.\n",
    "- Is it:\n",
    "    - tall and skinny, \n",
    "    - short and fat, \n",
    "    - or perfectly round"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# A very vague definition\n",
    "It can be mathematically characterized in many different very much unequal ways (in all cases 0 represents a sphere)\n",
    "\n",
    "$$ Aiso1 = \\frac{\\text{Longest Side}}{\\text{Shortest Side}} - 1 $$\n",
    "\n",
    "$$ Aiso2 = \\frac{\\text{Longest Side}-\\text{Shortest Side}}{\\text{Longest Side}} $$\n",
    "\n",
    "$$ Aiso3 = \\frac{\\text{Longest Side}}{\\text{Average Side Length}} - 1 $$\n",
    "\n",
    "$$ Aiso4 = \\frac{\\text{Longest Side}-\\text{Shortest Side}}{\\text{Average Side Length}} $$\n",
    "\n",
    "$$ \\cdots \\rightarrow \\text{ ad nauseum} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from skimage.measure import regionprops\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "xx, yy = np.meshgrid(np.linspace(-5, 5, 100),\n",
    "                     np.linspace(-5, 5, 100))\n",
    "\n",
    "\n",
    "def side_len(c_reg): return sorted(\n",
    "    [c_reg.bbox[3]-c_reg.bbox[1], c_reg.bbox[2]-c_reg.bbox[0]])\n",
    "\n",
    "\n",
    "aiso_funcs = [lambda x: side_len(x)[-1]/side_len(x)[0]-1,\n",
    "              lambda x: (side_len(x)[-1]-side_len(x)[0])/side_len(x)[-1],\n",
    "              lambda x: side_len(x)[-1]/np.mean(side_len(x))-1,\n",
    "              lambda x: (side_len(x)[-1]-side_len(x)[0])/np.mean(side_len(x))]\n",
    "\n",
    "\n",
    "def ell_func(a, b): return np.sqrt(np.square(xx/a)+np.square(yy/b)) <= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "format": "tab",
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib.animation import FuncAnimation\n",
    "from IPython.display import HTML\n",
    "fig, m_axs = plt.subplots(2, 3,\n",
    "                          figsize=(12, 8),\n",
    "                          dpi=72)\n",
    "ab_list = [(2, 2), (2, 3), (2, 4), (2, 5), (1.5, 5),\n",
    "           (1, 5), (0.5, 5), (0.1, 5),  (0.05, 5)]\n",
    "func_pts = defaultdict(list)\n",
    "\n",
    "\n",
    "def update_frame(i):\n",
    "    plt.cla()\n",
    "    a, b = ab_list[i]\n",
    "    c_img = ell_func(a, b)\n",
    "    m_axs[0, 0].imshow(c_img, cmap='gist_earth')\n",
    "    reg_info = regionprops(c_img.astype(int))[0]\n",
    "    m_axs[0, 0].set_title('Shape #{}'.format(i+1))\n",
    "    for j, (c_func, c_ax) in enumerate(zip(aiso_funcs, m_axs.flatten()[1:]), 1):\n",
    "        func_pts[j] += [c_func(reg_info)]\n",
    "        c_ax.plot(func_pts[j], 'r-')\n",
    "        c_ax.set_title('Anisotropy #{}'.format(j))\n",
    "        c_ax.set_ylim(-.1, 3)\n",
    "    m_axs.flatten()[-1].axis('off')\n",
    "\n",
    "\n",
    "# write animation frames\n",
    "anim_code = FuncAnimation(fig,\n",
    "                          update_frame,\n",
    "                          frames=len(ab_list)-1,\n",
    "                          interval=500,\n",
    "                          repeat_delay=1000).to_html5_video()\n",
    "plt.close('all')\n",
    "HTML(anim_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Useful Statistical Tools\n",
    "\n",
    "While many of the topics covered in \n",
    "\n",
    "- Linear Algebra \n",
    "- and Statistics courses \n",
    "\n",
    "might not seem very applicable to real problems at first glance.\n",
    "\n",
    "at least a few of them come in handy for dealing distributions of pixels \n",
    "\n",
    "_(they will only be briefly covered, for more detailed review look at some of the suggested material)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Principal Component Analysis\n",
    "- Similar to K-Means insofar as we start with a series of points in a vector space and want to condense the information. \n",
    "\n",
    "With PCA\n",
    "- doesn't search for distinct groups, \n",
    "- we find a linear combination of components which best explain the variance in the system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## PCA on spectroscopy\n",
    "As an example we will use a very simple example from spectroscopy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "format": "tab",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "cm_dm = np.linspace(1000, 4000, 300)\n",
    "\n",
    "\n",
    "def peak(cent, wid, h): return h/(wid*np.sqrt(2*np.pi)) * \\\n",
    "    np.exp(-np.square((cm_dm-cent)/wid))\n",
    "\n",
    "\n",
    "def peaks(plist): return np.sum(np.stack(\n",
    "    [peak(cent, wid, h) for cent, wid, h in plist], 0), 0)+np.random.uniform(0, 1, size=cm_dm.shape)\n",
    "\n",
    "\n",
    "fat_curve = [(2900, 100, 500), (1680, 200, 400)]\n",
    "protein_curve = [(2900, 50, 200), (3400, 100, 600), (1680, 200, 300)]\n",
    "noise_curve = [(3000, 50, 1)]\n",
    "\n",
    "fig, (ax0, ax1, ax2) = plt.subplots(1, 3, figsize=(12, 4))\n",
    "\n",
    "ax1.plot(cm_dm, peaks(fat_curve))\n",
    "ax1.set_title('Fat IR Spectra')\n",
    "\n",
    "ax2.plot(cm_dm, peaks(protein_curve))\n",
    "ax2.set_title('Protein IR Spectra')\n",
    "\n",
    "ax0.plot(cm_dm, peaks(noise_curve))\n",
    "ax0.set_title('Noise IR Spectra')\n",
    "\n",
    "ax0.set_ylim(ax2.get_ylim())\n",
    "ax2.set_ylim(ax2.get_ylim())\n",
    "\n",
    "pd.DataFrame({'cm^(-1)': cm_dm, 'intensity': peaks(protein_curve)}).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Test Dataset of a number of curves\n",
    "We want to sort cells or samples into groups of being \n",
    "- more fat like \n",
    "- or more protein like. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## How can we analyze this data without specifically looking for peaks or building models?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "format": "tab",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "test_data = np.stack([peaks(c_curve) for _ in range(20)\n",
    "                      for c_curve in [protein_curve, fat_curve, noise_curve]], 0)\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "ax1.plot(test_data[:4].T, '.-')\n",
    "ax1.legend(['Curve 1', 'Curve 2', 'Curve 3', 'Curve 4'])\n",
    "ax1.set_title('Data curves with peaks')\n",
    "ax2.scatter(test_data[:, 0], test_data[:,1], c=range(test_data.shape[0]),\n",
    "            s=20, cmap='nipy_spectral')\n",
    "ax2.set_title('Scatter plot of curve 1 and 2'); ax2.set_xlabel('Curve 1'); ax2.set_ylabel('Curve 2'); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "format": "column",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca_tool = PCA(5)\n",
    "pca_tool.fit(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "format": "tab",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "score_matrix = pca_tool.transform(test_data)\n",
    "ax1.plot(cm_dm, pca_tool.components_[0, :], label='Component #1')\n",
    "ax1.plot(cm_dm, pca_tool.components_[\n",
    "         1, :], label='Component #2', alpha=pca_tool.explained_variance_ratio_[0])\n",
    "ax1.plot(cm_dm, pca_tool.components_[\n",
    "         2, :], label='Component #3', alpha=pca_tool.explained_variance_ratio_[1])\n",
    "ax1.legend(), ax1.set_title('Components')\n",
    "ax2.scatter(score_matrix[:, 0],\n",
    "            score_matrix[:, 1])\n",
    "ax2.set_xlabel('Component 1')\n",
    "ax2.set_ylabel('Component 2');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "format": "tab",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(1, 1, figsize=(8, 4), dpi=100)\n",
    "ax1.bar(x=range(pca_tool.explained_variance_ratio_.shape[0]),\n",
    "        height=100*pca_tool.explained_variance_ratio_)\n",
    "ax1.set_xlabel('Components')\n",
    "ax1.set_ylabel('Explained Variance (%)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Principal Component Analysis\n",
    "## scikit-learn [Face Analyis](http://scikit-learn.org/stable/auto_examples/decomposition/plot_faces_decomposition.html)\n",
    "\n",
    "Here we show a more imaging related example from the scikit-learn documentation where we do basic face analysis with scikit-learn.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "format": "tab",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_olivetti_faces\n",
    "from sklearn import decomposition\n",
    "# Load faces data\n",
    "try:\n",
    "    dataset = fetch_olivetti_faces(\n",
    "        shuffle=True, random_state=2018, data_home='.')\n",
    "    faces = dataset.data\n",
    "except Exception as e:\n",
    "    print('Face data not available', e)\n",
    "    faces = np.random.uniform(0, 1, (400, 4096))\n",
    "\n",
    "n_samples, n_features = faces.shape\n",
    "n_row, n_col = 2, 3\n",
    "n_components = n_row * n_col\n",
    "image_shape = (64, 64)\n",
    "\n",
    "# global centering\n",
    "faces_centered = faces - faces.mean(axis=0)\n",
    "\n",
    "# local centering\n",
    "faces_centered -= faces_centered.mean(axis=1).reshape(n_samples, -1)\n",
    "\n",
    "print(\"Dataset consists of %d faces\" % n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "format": "tab",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def plot_gallery(title, images, n_col=n_col, n_row=n_row):\n",
    "    plt.figure(figsize=(2. * n_col, 2.26 * n_row))\n",
    "    plt.suptitle(title, size=16)\n",
    "    for i, comp in enumerate(images):\n",
    "        plt.subplot(n_row, n_col, i + 1)\n",
    "        vmax = max(comp.max(), -comp.min())\n",
    "        plt.imshow(comp.reshape(image_shape), cmap=plt.cm.gray,\n",
    "                   interpolation='nearest',\n",
    "                   vmin=-vmax, vmax=vmax)\n",
    "        plt.xticks(())\n",
    "        plt.yticks(())\n",
    "    plt.subplots_adjust(0.01, 0.05, 0.99, 0.93, 0.04, 0.)\n",
    "\n",
    "\n",
    "# #############################################################################\n",
    "# List of the different estimators, whether to center and transpose the\n",
    "# problem, and whether the transformer uses the clustering API.\n",
    "estimators = [\n",
    "    ('Eigenfaces - PCA using randomized SVD',\n",
    "     decomposition.PCA(n_components=n_components, svd_solver='randomized',\n",
    "                       whiten=True),\n",
    "     True)]\n",
    "# #############################################################################\n",
    "# Plot a sample of the input data\n",
    "\n",
    "plot_gallery(\"First centered Olivetti faces\", faces_centered[:n_components])\n",
    "\n",
    "# #############################################################################\n",
    "# Do the estimation and plot it\n",
    "\n",
    "for name, estimator, center in estimators:\n",
    "    print(\"Extracting the top %d %s...\" % (n_components, name))\n",
    "    data = faces\n",
    "    if center:\n",
    "        data = faces_centered\n",
    "    estimator.fit(data)\n",
    "\n",
    "    if hasattr(estimator, 'cluster_centers_'):\n",
    "        components_ = estimator.cluster_centers_\n",
    "    else:\n",
    "        components_ = estimator.components_\n",
    "    plot_gallery(name,\n",
    "                 components_[:n_components])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Applied PCA: Shape Tensor\n",
    "\n",
    "## How do these statistical analyses help us?\n",
    "Going back to a single cell, we have the a distribution of $x$ and $y$ values.\n",
    "- are not however completely independent\n",
    "- greatest variance does not normally lie in either x nor y alone. \n",
    "\n",
    "A principal component analysis of the voxel positions, will calculate two new principal components (the components themselves are the relationships between the input variables and the scores are the final values.)\n",
    "- An optimal rotation of the coordinate system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We start off by calculating the covariance matrix from the list of $x$, $y$, and $z$ points that make up our object of interest.\n",
    "\n",
    "$$ COV(I_{id}) = \\frac{1}{N} \\sum_{\\forall\\vec{v}\\in I_{id}} \\begin{bmatrix}\n",
    "\\vec{v}_x\\vec{v}_x & \\vec{v}_x\\vec{v}_y & \\vec{v}_x\\vec{v}_z\\\\\n",
    "\\vec{v}_y\\vec{v}_x & \\vec{v}_y\\vec{v}_y & \\vec{v}_y\\vec{v}_z\\\\\n",
    "\\vec{v}_z\\vec{v}_x & \\vec{v}_z\\vec{v}_y & \\vec{v}_z\\vec{v}_z\n",
    "\\end{bmatrix} $$\n",
    "\n",
    "We then take the eigentransform of this array to obtain the eigenvectors (principal components, $\\vec{\\Lambda}_{1\\cdots 3}$) and eigenvalues (scores, $\\lambda_{1\\cdots 3}$)\n",
    "\n",
    "$$ COV(I_{id}) \\longrightarrow \\underbrace{\\begin{bmatrix}\n",
    "\\vec{\\Lambda}_{1x} & \\vec{\\Lambda}_{1y} & \\vec{\\Lambda}_{1z} \\\\\n",
    "\\vec{\\Lambda}_{2x} & \\vec{\\Lambda}_{2y} & \\vec{\\Lambda}_{2z} \\\\\n",
    "\\vec{\\Lambda}_{3x} & \\vec{\\Lambda}_{3y} & \\vec{\\Lambda}_{3z} \n",
    "\\end{bmatrix}}_{\\textrm{Eigenvectors}} * \\underbrace{\\begin{bmatrix} \n",
    "\\lambda_1 & 0 & 0 \\\\ \n",
    "0 & \\lambda_2 & 0 \\\\\n",
    "0 & 0 & \\lambda_3\n",
    "\\end{bmatrix}}_{\\textrm{Eigenvalues}} * \\underbrace{\\begin{bmatrix}\n",
    "\\vec{\\Lambda}_{1x} & \\vec{\\Lambda}_{1y} & \\vec{\\Lambda}_{1z} \\\\\n",
    "\\vec{\\Lambda}_{2x} & \\vec{\\Lambda}_{2y} & \\vec{\\Lambda}_{2z} \\\\\n",
    "\\vec{\\Lambda}_{3x} & \\vec{\\Lambda}_{3y} & \\vec{\\Lambda}_{3z} \n",
    "\\end{bmatrix}^{T}}_{\\textrm{Eigenvectors}} $$\n",
    "The principal components tell us about the orientation of the object and the scores tell us about the corresponding magnitude (or length) in that direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "format": "column",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "from skimage.io import imread\n",
    "from skimage.morphology import label\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "seg_img = imread('ext-figures/aachen_label.png') == 26\n",
    "seg_img = seg_img[::4, ::4]\n",
    "seg_img = seg_img[110:130:2, 378:420:3] > 0\n",
    "seg_img = np.pad(seg_img, 3, mode='constant')\n",
    "seg_img[0, 0] = 0\n",
    "_, (ax1) = plt.subplots(1, 1, figsize=(7, 7), dpi=100)\n",
    "ax1.matshow(seg_img, cmap='bone_r');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "x_coord, y_coord = np.where(seg_img > 0)\n",
    "xy_pts = np.stack([x_coord, y_coord], 1)\n",
    "shape_pca = PCA()\n",
    "shape_pca.fit(xy_pts)\n",
    "pca_xy_vals = shape_pca.transform(xy_pts)\n",
    "_, (ax1) = plt.subplots(1, 1,\n",
    "                        figsize=(7, 7),\n",
    "                        dpi=100)\n",
    "ax1.plot(pca_xy_vals[:, 0], pca_xy_vals[:, 1], 'rs', markersize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "_, (ax1) = plt.subplots(1, 1,\n",
    "                        figsize=(7, 7),\n",
    "                        dpi=100)\n",
    "\n",
    "\n",
    "ax1.plot(xy_pts[:, 0]-np.mean(xy_pts[:, 0]),\n",
    "         xy_pts[:, 1]-np.mean(xy_pts[:, 1]), 'rs', label='Points')\n",
    "ax1.plot([0, shape_pca.explained_variance_[0]/2*shape_pca.components_[0, 0]],\n",
    "         [0, shape_pca.explained_variance_[0]/2*shape_pca.components_[0, 1]], 'b-',\n",
    "         label='PCA1'\n",
    "         )\n",
    "ax1.plot([0, shape_pca.explained_variance_[1]/2*shape_pca.components_[1, 0]],\n",
    "         [0, shape_pca.explained_variance_[1]/2*shape_pca.components_[1, 1]], 'g-',\n",
    "         label='PCA2'\n",
    "         )\n",
    "ax1.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Principal Component Analysis: Take home message\n",
    "\n",
    "- We calculate the statistical distribution individually for $x$, $y$, and $z$ and the 'correlations' between them.\n",
    "- From these values we can estimate the orientation in the direction of largest variance\n",
    "- We can also estimate magnitude\n",
    "- These functions are implemented as ```princomp``` or ```pca``` in various languages and scale well to very large datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Principal Component Analysis: Elliptical Model\n",
    "\n",
    "\n",
    "While the eigenvalues and eigenvectors are in their own right useful\n",
    "- Not obvious how to visually represent these tensor objects\n",
    "- Ellipsoidal (Ellipse in 2D) representation alleviates this issue\n",
    "\n",
    "### Ellipsoidal Representation\n",
    "1. Center of Volume is calculated normally\n",
    "1. Eigenvectors represent the unit vectors for the semiaxes of the ellipsoid\n",
    "1. $\\sqrt{\\text{Eigenvalues}}$ is proportional to the length of the semiaxis ($\\mathcal{l}=\\sqrt{5\\lambda_i}$), derivation similar to moment of inertia tensor for ellipsoids.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Meshing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "# Meshing\n",
    "\n",
    "The process of turning a (connected) set of pixels into a list of vertices and edges\n",
    "\n",
    "- For these vertices and edges we can define forces. \n",
    "- Most crucially this comes when looking at physical processes like deformation.\n",
    "- Meshes are also useful for visualization.\n",
    "\n",
    "\n",
    "### Example\n",
    "Looking at stress-strain relationships in mechanics using Hooke's Model \n",
    "\n",
    "$$ \\vec{F}=k (\\vec{x}_0-\\vec{x}) $$ \n",
    "\n",
    "the force needed to stretch one of these edges is proportional to how far it is stretched. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Meshing\n",
    "\n",
    "\n",
    "Since we uses voxels to image and identify the volume we can use the voxels themselves as an approimation for the surface of the structure. \n",
    "- Each 'exposed' face of a voxel belongs to the surface\n",
    "\n",
    "From this we can create a mesh by \n",
    "\n",
    "- adding each exposed voxel face to a list of surface squares. \n",
    "- adding connectivity information for the different squares (shared edges and vertices)\n",
    "\n",
    "A wide variety of methods of which we will only graze the surface (http://en.wikipedia.org/wiki/Image-based_meshing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Marching Cubes\n",
    "\n",
    "### Why\n",
    "Voxels are very poor approximations for the surface and are very rough (they are either normal to the x, y, or z axis and nothing between).\n",
    "\n",
    "<img src=\"../common/figures/sphere_comparison.svg\" style=\"height:150px\" />\n",
    "\n",
    "### [How](https://en.wikipedia.org/wiki/Marching_cubes)\n",
    "1. The image is processed one voxel at a time \n",
    "2. The 2x2x2 neighborhood is checked at every voxel. \n",
    "3. From this configuration of values, faces are added to the mesh to incorporate the most simple surface which would explain the values. \n",
    "\n",
    "This algortihm is nicely explained in this [video](https://youtu.be/M3iI2l0ltbE)\n",
    "\n",
    "[Marching tetrahedra](http://en.wikipedia.org/wiki/Marching_tetrahedra) is for some applications a better suited approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Next Time on QBI\n",
    "\n",
    "\n",
    "So, while bounding box and ellipse-based models are useful for many object and cells, they do a very poor job with other samples\n",
    "\n",
    "\n",
    "***\n",
    "\n",
    "### Why\n",
    "- We assume an entity consists of connected pixels (wrong)\n",
    "- We assume the objects are well modeled by an ellipse (also wrong)\n",
    "\n",
    "### What to do?\n",
    "\n",
    "- Is it 3 connected objects which should all be analzed seperately?\n",
    "- If we could __divide it__, we could then analyze each spart as an ellipse\n",
    "- Is it one network of objects and we want to know about the constrictions?\n",
    "- Is it a cell or organelle with docking sites for cell?\n",
    "- Neither extents nor anisotropy are very meaningful, we need a __more specific metric__ which can characterize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "livereveal": {
   "autolaunch": true,
   "scroll": true
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "321px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
