{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# ETHZ: 227-0966-00L\n",
    "# Quantitative Big Imaging\n",
    "# April 16, 2019\n",
    "\n",
    "## Statistics and Reproducibility\n",
    "\n",
    "#### Anders Kaestner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (8, 8)\n",
    "plt.rcParams[\"figure.dpi\"] = 150\n",
    "plt.rcParams[\"font.size\"] = 14\n",
    "plt.rcParams['font.family'] = ['sans-serif']\n",
    "plt.rcParams['font.sans-serif'] = ['DejaVu Sans']\n",
    "plt.style.use('ggplot')\n",
    "sns.set_style(\"whitegrid\", {'axes.grid': False})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Literature / Useful References\n",
    "\n",
    "### Books\n",
    "- Jean Claude, Morphometry with R\n",
    " - [Online](http://link.springer.com/book/10.1007%2F978-0-387-77789-4) through ETHZ\n",
    " - __Chapter 3__\n",
    " - [Buy it](http://www.amazon.com/Morphometrics-R-Use-Julien-Claude/dp/038777789X)\n",
    "- John C. Russ, âThe Image Processing Handbookâ,(Boca Raton, CRC Press)\n",
    " - Available [online](http://dx.doi.org/10.1201/9780203881095) within domain ethz.ch (or proxy.ethz.ch / public VPN) \n",
    "- [Hypothesis Testing Chapter](http://www.sagepub.com/upm-data/40007_Chapter8.pdf)\n",
    "- Grammar of Graphics: Leland and Wilkinson - http://www.springer.com/gp/book/9780387245447"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Videos / Podcasts\n",
    "- Google/Stanford Statistics Intro\n",
    " - https://www.youtube.com/watch?v=YFC2KUmEebc\n",
    "- MCB 140 P-value lecture at UC Berkeley (Audio)\n",
    " - https://itunes.apple.com/us/itunes-u/mcb-140-fall-2007-general/id461120088?mt=10\n",
    "- Correlation and Causation (Video)\n",
    " - https://www.youtube.com/watch?v=YFC2KUmEebc\n",
    "- Last Week Tonight: Scientific Studies\n",
    " - https://www.youtube.com/watch?v=0Rnq1NpHdmw\n",
    "- Credibility Crisis \n",
    " - https://www.datacamp.com/community/podcast/credibility-crisis-in-data-science"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Slides\n",
    "- How to solve NLP problems\n",
    " - https://twitter.com/sleepinyourhat/status/1105946169165955073?s=20\n",
    "- Data Visualization\n",
    " - https://socviz.co/lookatdata.html\n",
    "- P-Values with Puppies\n",
    " - https://hackernoon.com/explaining-p-values-with-puppies-af63d68005d0\n",
    "\n",
    "### Model Evaluation\n",
    "\n",
    "- [Julia Evans - Recalling with Precision](https://www.youtube.com/watch?v=ryZL4XNUmwo)\n",
    "- [Stripe's Next Top Model](https://github.com/stripe/topmodel)\n",
    "\n",
    "### Iris Dataset\n",
    "\n",
    "- The Iris dataset was used in Fisher's classic 1936 paper, The Use of Multiple Measurements in Taxonomic Problems: http://rcs.chemometrics.ru/Tutorials/classification/Fisher.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Papers / Sites\n",
    "- [Matlab Unit Testing Documentation](http://www.mathworks.ch/ch/help/matlab/matlab-unit-test-framework.html\n",
    ")\n",
    "- [Databases Introduction](http://swcarpentry.github.io/sql-novice-survey/)\n",
    "- [Visualizing Genomic Data](http://circos.ca/documentation/course/visualizing-genomic-data.pdf) (General Visualization Techniques)\n",
    "- [NIMRod Parameter Studies](http://www.messagelab.monash.edu.au/nimrod)\n",
    "\n",
    "- M.E. Wolak, D.J. Fairbairn, Y.R. Paulsen (2012) Guidelines for Estimating Repeatability. Methods in Ecology and Evolution 3(1):129-137.\n",
    "- David J.C. MacKay, Bayesian Interpolartion (1991) [http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.27.9072]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Previously on QBI ...\n",
    "\n",
    "- Image Enhancment \n",
    " - Highlighting the contrast of interest in images\n",
    " - Minimizing Noise\n",
    "- Understanding image histograms\n",
    "- Automatic Methods\n",
    "- Component Labeling\n",
    "- Single Shape Analysis\n",
    "- Complicated Shapes\n",
    "- Dynamic Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Quantitative \"Big\" Imaging\n",
    "\n",
    "\n",
    "The course has covered imaging enough and there have been a few quantitative metrics, but \"big\" has not really entered.\n",
    "\n",
    "What does __big__ mean?\n",
    "\n",
    "- Not just / even large\n",
    "- it means being ready for _big data_\n",
    "- volume, velocity, variety (3 V's)\n",
    "- scalable, fast, easy to customize\n",
    "\n",
    "\n",
    "So what is \"big\" imaging\n",
    "\n",
    "####  >>>> doing analyses in a disciplined manner <<<<\n",
    "\n",
    " - fixed steps\n",
    " - easy to regenerate results\n",
    " - no _magic_\n",
    " \n",
    "#### having everything automated\n",
    "\n",
    " - 100 samples is as easy as 1 sample\n",
    " \n",
    "#### being able to adapt and reuse analyses\n",
    "\n",
    " - one really well working script and modify parameters\n",
    " - different types of cells\n",
    " - different regions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Objectives\n",
    "\n",
    "1. Scientific Studies all try to get to a single number\n",
    " - Make sure this number is describing the structure well (what we have covered before)\n",
    " - Making sure the number is meaningful (__today!__)\n",
    "1. How do we compare the number from different samples and groups?\n",
    " - Within a sample or same type of samples\n",
    " - Between samples\n",
    "1. How do we compare different processing steps like filter choice, minimum volume, resolution, etc?\n",
    "1. How do we evaluate our parameter selection?\n",
    "1. How can we ensure our techniques do what they are supposed to do?\n",
    "1. How can we visualize so much data? Are there rules?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Outline\n",
    "\n",
    "- Motivation (Why and How?)\n",
    "- Scientific Goals\n",
    "- Reproducibility\n",
    "- Predicting and Validating\n",
    "- Statistical metrics and results\n",
    "- Parameterization\n",
    " - Parameter sweep\n",
    " - Sensitivity analysis\n",
    "- Unit Testing\n",
    "- Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# What do we start with?\n",
    "\n",
    "Going back to our original cell image\n",
    "\n",
    "1. We have been able to get rid of the noise in the image and find all the cells (lecture 2-4)\n",
    "1. We have analyzed the shape of the cells using the shape tensor (lecture 5)\n",
    "1. We even separated cells joined together using Watershed (lecture 6)\n",
    "1. We have created even more metrics characterizing the distribution (lecture 7)\n",
    "\n",
    "We have at least a few samples (or different regions), large number of metrics and an almost as large number of parameters to _tune_\n",
    "\n",
    "### How do we do something meaningful with it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Correlation and Causation\n",
    "\n",
    "\n",
    "One of the most repeated criticisms of scientific work is that correlation and causation are confused. \n",
    "\n",
    "1. Correlation \n",
    " - means a statistical relationship\n",
    " - very easy to show (single calculation)\n",
    "2. Causation \n",
    " - implies there is a mechanism between A and B\n",
    " - very difficult to show (impossible to prove)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Observational or Controlled\n",
    "\n",
    "There are two broad classes of data and scientific studies. \n",
    "<table>\n",
    "<col width=\"400px\" />\n",
    "<tr><th>Observational</th><th>Controlled</th></tr>    \n",
    "<tr><td><img src=\"../common/figures/noun_MuseumVisit.svg\" /></td>\n",
    "<td><img src=\"../common/figures/noun_puppet.svg\" /></td><tr>\n",
    "    </table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Observational\n",
    "\n",
    " - Exploring large datasets looking for trends\n",
    " - Population is random\n",
    " - Not always hypothesis driven\n",
    " - Rarely leads to causation\n",
    "\n",
    "\n",
    "#### Examples\n",
    "- We examined 100 people \n",
    "    - the ones with blue eyes were on average 10cm taller\n",
    "    \n",
    "- In 100 cake samples\n",
    "    - we found a 0.9 correlation between cooking time and bubble size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Controlled\n",
    "\n",
    " - Most scientific studies fall into this category\n",
    " - Specifics of the groups are controlled\n",
    " - Can lead to causation\n",
    "\n",
    "#### Examples\n",
    "- We examined 50 mice with gene XYZ off and 50 gene XYZ on and as the foot size increased by 10%\n",
    "- We increased the temperature and the number of pores in the metal increased by 10%\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Simple Model: Magic / Weighted Coin\n",
    "\n",
    "\n",
    "\n",
    "Since most of the experiments in science are usually specific, noisy, and often very complicated and are not usually good teaching examples\n",
    "\n",
    "### Magic / Biased Coin\n",
    "You buy a _magic_ coin at a shop\n",
    "\n",
    "#### How many times do you need to flip it to _prove_ it is not fair?\n",
    " - If I flip it 10 times and another person flips it 10 times, is that the same as 20 flips?\n",
    " - If I flip it 10 times and then multiply the results by 10 is that the same as 100 flips?\n",
    " - If I buy 10 coins and want to know which ones are fair what do I do?\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Simple Model: Magic / Weighted Coin\n",
    "\n",
    "\n",
    "1. Each coin represents a stochastic variable $\\mathcal{X}$ and each flip represents an observation $\\mathcal{X}_i$.\n",
    "1. The act of performing a coin flip $\\mathcal{F}$ is an observation $\\mathcal{X}_i = \\mathcal{F}(\\mathcal{X})$\n",
    "\n",
    "We normally assume\n",
    "\n",
    "1. A _fair_ coin has an expected value of $E(\\mathcal{X})=\\frac{1}{2}$:\n",
    "    - 50% Heads, \n",
    "    - 50% Tails\n",
    "    \n",
    "1. An _unbiased_ flip(er) means  _each flip is independent of the others_\n",
    "\n",
    "$$ P(\\mathcal{F}_1(\\mathcal{X})*\\mathcal{F}_2(\\mathcal{X}))= P(\\mathcal{F}_1(\\mathcal{X}))*P(\\mathcal{F}_2(\\mathcal{X}))$$\n",
    "\n",
    " - the expected value of the flip is the same as that of the coin\n",
    " \n",
    "$$ E(\\prod_{i=0}^\\infty \\mathcal{F}_i(\\mathcal{X})) = E(\\mathcal{X}) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Simple Model to Reality\n",
    "\n",
    "\n",
    "### Coin Flip\n",
    "\n",
    "1. Each flip gives us a small piece of information about \n",
    "    - the coin \n",
    "    - _and_ the flipper\n",
    "    \n",
    "2. More flips provides more information\n",
    " - __Random / Stochastic variations__ in coin and flipper __cancel out__\n",
    " - __Systematic variations accumulate__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Simple Model to Reality\n",
    "\n",
    "### Real Experiment\n",
    "\n",
    "1. Each measurement tells us about \n",
    "    - our sample, \n",
    "    - our instrument, \n",
    "    - and our analysis\n",
    "2. More measurements provide more information\n",
    " - Random / Stochastic variations in sample, instrument, and analysis cancel out\n",
    " - _Normally_ the analysis has very little to no stochastic variation\n",
    " - Systematic variations accumulate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Iris: A more complicated model\n",
    "\n",
    "Coin flips are very simple and probably difficult to match to another experiment. \n",
    "\n",
    "A very popular dataset for learning about such values beyond 'coin-flips' is called the [Iris dataset](http://archive.ics.uci.edu/ml/datasets/iris) which covers\n",
    "- a number of measurements \n",
    "- from different plants \n",
    "- and the corresponding species.\n",
    "\n",
    "<center>\n",
    "<img src=\"../common/figures/Iris.png\" style=\"height:300px\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Let's load the Iris data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "data = load_iris()\n",
    "iris_df = pd.DataFrame(data['data'], columns=data['feature_names'])\n",
    "iris_df['target'] = data['target_names'][data['target']]\n",
    "iris_df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## A first inspection of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "sns.pairplot(iris_df, hue='target');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Comparing Groups: Intraclass Correlation Coefficient\n",
    "\n",
    "\n",
    "The intraclass correlation coefficient basically looking at \n",
    "- how similar objects within a group are \n",
    "- compared to the similarity between groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Looking at the sepal data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "format": "column",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "fig,(ax1,ax2) = plt.subplots(1,2,figsize=(15,5))\n",
    "sns.swarmplot(data=iris_df, ax = ax1,\n",
    "               x='target', y='sepal width (cm)');ax1.set_title('Low Group Similarity');\n",
    "ax2.imshow(plt.imread('../common/figures/FlowerAnatomy.png')); ax2.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Looking at the patal data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "format": "column",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "fig,(ax1,ax2) = plt.subplots(1,2,figsize=(15,5))\n",
    "g = sns.swarmplot(data=iris_df, ax=ax1,\n",
    "               x='target', y='petal length (cm)');g.set_title('High Group Similarity');\n",
    "ax2.imshow(plt.imread('../common/figures/FlowerAnatomy.png')); ax2.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Making quantitative statements\n",
    "## Intraclass Correlation Coefficient Definition\n",
    "\n",
    "$$ ICC = \\frac{S_A^2}{S_A^2+S_W^2} $$\n",
    "\n",
    "where \n",
    "- $S_A^2$ is the variance among groups or classes\n",
    " - Estimate with the standard deviations of the mean values for each group \n",
    "- $S_W^2$ is the variance within groups or classes.\n",
    " - Estimate with the average of standard deviations for each group\n",
    "\n",
    "### Interpretation\n",
    "$$\n",
    "ICC = \\left\\{\\begin{array}{cl} \n",
    "1 & \\mbox{means 100% of the variance is between classes} \\\\\n",
    "0 & \\mbox{means 0% of the variance is between classes}\n",
    "\\end{array}\\right.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Intraclass Correlation Coefficient: Values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "format": "tab",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def icc_calc(value_name, group_name, data_df):\n",
    "    data_agg = data_df.groupby(group_name).agg({value_name: ['mean', 'var']}).reset_index()\n",
    "    data_agg.columns = data_agg.columns.get_level_values(1)\n",
    "    S_w = data_agg['var'].mean()\n",
    "    S_a = data_agg['mean'].var()\n",
    "    return S_a/(S_a+S_w)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "sns.swarmplot(data=iris_df, ax=ax1,\n",
    "               x='target', y='sepal width (cm)')\n",
    "ax1.set_title('Low Group Similarity\\nICC:{:2.1%}'.format(icc_calc('sepal width (cm)', 'target', iris_df)));\n",
    "\n",
    "sns.swarmplot(data=iris_df,ax=ax2, \n",
    "               x='target', y='petal length (cm)')\n",
    "ax2.set_title('High Group Similarity\\nICC:{:2.1%}'.format(icc_calc('petal length (cm)', 'target', iris_df)));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Comparing Groups: Tests\n",
    "\n",
    "\n",
    "Once the reproducibility has been measured, it is possible to compare groups. \n",
    "\n",
    "The idea is to make a test to assess the likelihood that two groups are the same given the data\n",
    "\n",
    "1. List assumptions\n",
    "1. Establish a null hypothesis\n",
    " - Usually that both groups are the same\n",
    "1. Calculate the probability of the observations given the truth of the null hypothesis\n",
    " - Requires knowledge of probability distribution of the data\n",
    " - Modeling can be exceptionally complicated\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Loaded Coin example\n",
    "\n",
    "We have 1 coin from a magic shop.\n",
    "\n",
    "- Our assumptions are:\n",
    " - we flip and observe flips of coins accurately and independently\n",
    " - the coin is invariant and always has the same expected value\n",
    " \n",
    " \n",
    "- Our null hypothesis is the coin is unbiased $E(\\mathcal{X})=0.5$\n",
    "- we can calculate the likelihood of a given observation given the number of flips ([p-value](https://en.wikipedia.org/wiki/P-value))\n",
    "\n",
    "<center>\n",
    "<img src=\"../common/figures/p-value.svg\" style=\"height:300px\"/>\n",
    "</center>\n",
    "\n",
    "How good is good enough?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Comparing Groups: Student's T Distribution\n",
    "\n",
    "- Since we do not usually know our distribution very well \n",
    "- _or_ have enough samples to create a sufficient probability model\n",
    "\n",
    "### [Student T Distribution](http://en.wikipedia.org/wiki/Student's_t-distribution)\n",
    "We assume the distribution of our stochastic variable is normal (Gaussian) and the t-distribution provides an estimate for the mean of the underlying distribution based on few observations.\n",
    "\n",
    "- We estimate the likelihood of our observed values assuming they are coming from random observations of a normal process\n",
    "\n",
    "\n",
    "\n",
    "### [Student T-Test](https://en.wikipedia.org/wiki/Student%27s_t-test)\n",
    "\n",
    "Incorporates this distribution and provides an easy method for assessing the likelihood that the two given set of observations are coming from the same underlying process (null hypothesis)\n",
    "\n",
    "- Assume unbiased observations\n",
    "- Assume normal distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Multiple Testing Bias\n",
    "\n",
    "\n",
    "Back to the magic coin, let's assume we are trying to publish a paper, \n",
    "- we heard a p-value of < 0.05 (5%) was good enough. \n",
    "- That means if we get 5 heads we are good!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Probability with increasing number of tosses\n",
    "\n",
    "$$ P = \\prod_i P(\\mathcal{F}_i(\\mathcal{X}))$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "format": "column",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import ttest_ind\n",
    "from IPython.display import display\n",
    "all_heads_df = pd.DataFrame({'n_flips': [1, 4, 5]})\n",
    "all_heads_df['Probability of # Heads'] = all_heads_df['n_flips'].map(\n",
    "    lambda x: '{:2.1%}'.format(0.5**x))\n",
    "display(all_heads_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Probability with many experiments\n",
    "Let N friends make 5 tosses..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "format": "column",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "friends_heads_df = pd.DataFrame({'n_friends': [1, 10, 20, 40, 80]})\n",
    "friends_heads_df['Probability of 5 Heads'] = friends_heads_df['n_friends'].map(\n",
    "    lambda n_friends: '{:2.1%}'.format((1-(1-0.5**5)**n_friends)))\n",
    "display(friends_heads_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Clearly this is not the case, otherwise we could keep flipping coins or ask all of our friends to flip until we got 5 heads and publish\n",
    "\n",
    "The p-value is only meaningful when the experiment matches what we did. \n",
    "#### We didn't say the chance of getting 5 heads ever was < 5%\n",
    "#### We said is if we have \n",
    "- exactly 5 observations \n",
    "- and all of them are heads \n",
    "- the likelihood that a fair coin produced that result is <5%\n",
    "\n",
    "#### There are many [methods](http://en.wikipedia.org/wiki/Multiple_comparisons_problem) to correct.\n",
    "\n",
    "Most just involve scaling $p$: \n",
    "- The likelihood of a sequence of 5 heads in a row if you perform 10 flips is 5x higher."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Multiple Testing Bias: Experiments\n",
    "\n",
    "\n",
    "This is very bad news for us. We have the ability to quantify all sorts of interesting metrics \n",
    "- cell distance to other cells\n",
    "- cell oblateness\n",
    "- cell distribution oblateness\n",
    "\n",
    "So lets throw them all into a magical statistics algorithm and push the __publish__ button\n",
    "\n",
    "\n",
    "With our p value of less than 0.05 and a study with 10 samples in each group, how does increasing the number of variables affect our result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "format": "column",
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('precision', 2)\n",
    "np.random.seed(2017)\n",
    "\n",
    "def random_data_maker(rows, cols):\n",
    "    data_df = pd.DataFrame(\n",
    "        np.random.uniform(-1, 1, size=(rows, cols)),\n",
    "        columns=['Var_{:02d}'.format(c_col) for c_col in range(cols)])\n",
    "    data_df['Group'] = [1]*(rows-rows//2)+[2]*(rows//2)\n",
    "    return data_df\n",
    "\n",
    "rand_df = random_data_maker(10, 5)\n",
    "\n",
    "rand_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "format": "column",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "\n",
    "\n",
    "def show_significant(in_df, cut_off=0.05):\n",
    "    return in_df.sort_values('P-Value').style.apply(lambda x: ['background-color: yellow' if v<cut_off else '' for v in x])\n",
    "\n",
    "\n",
    "def all_ttest(in_df):\n",
    "    return pd.DataFrame(\n",
    "        {'P-Value': {c_col: ttest_ind(\n",
    "            a=in_df[in_df['Group'] == 1][c_col],\n",
    "            b=in_df[in_df['Group'] == 2][c_col]\n",
    "        ).pvalue\n",
    "            for c_col in\n",
    "            in_df.columns if 'Group' not in c_col}})\n",
    "\n",
    "\n",
    "show_significant(all_ttest(rand_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(2019)\n",
    "show_significant(all_ttest(random_data_maker(150, 20)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from tqdm import notebook # progressbar\n",
    "out_list = []\n",
    "for n_vars in notebook.tqdm(range(1, 150, 10)):\n",
    "    for _ in range(50):\n",
    "        p_values = all_ttest(random_data_maker(100, n_vars)).values\n",
    "        out_list += [{'Variables in Study': n_vars,\n",
    "                      'Significant Variables Found': np.sum(p_values < 0.05),\n",
    "                     'raw_values': p_values}]\n",
    "var_found_df = pd.DataFrame(out_list)\n",
    "sns.swarmplot(data=var_found_df, x='Variables in Study', y='Significant Variables Found');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,7))\n",
    "sns.boxplot(data=var_found_df,\n",
    "            x='Variables in Study', y='Significant Variables Found');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Multiple Testing Bias: Correction\n",
    "\n",
    "Using the simple correction factor (number of tests performed), we can make the significant findings constant again. \n",
    "$$ p_{cutoff} = \\frac{0.05}{\\textrm{# of Tests}} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "var_found_df['Corrected Significant Count'] = var_found_df['raw_values'].map(lambda p_values: \n",
    "                                                                             np.sum(p_values<0.05/len(p_values)))\n",
    "\n",
    "var_found_df.groupby('Variables in Study').agg('mean').reset_index().plot('Variables in Study', [\n",
    "    'Significant Variables Found',\n",
    "    'Corrected Significant Count'\n",
    "]);\n",
    "plt.title('Effect of significance correction');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "So no harm done there we just add this correction factor right?\n",
    "\n",
    "Well, what if we have exactly one variable with shift of 1.0 standard deviations from the other. \n",
    "\n",
    "In a dataset where we check $n$ variables?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "table_df = random_data_maker(50, 10)\n",
    "really_different_var = np.concatenate([\n",
    "    np.random.normal(loc=0, scale=1.0, size=(table_df.shape[0]//2)),\n",
    "    np.random.normal(loc=1, scale=1.0, size=(table_df.shape[0]//2))\n",
    "])\n",
    "table_df['Really Different Var'] = really_different_var\n",
    "fig, ax1 = plt.subplots(1, 1, figsize=(10, 5))\n",
    "ax1.hist(table_df.query('Group==1')['Really Different Var'], np.linspace(-5, 5, 20), label='Group 1')\n",
    "ax1.hist(table_df.query('Group==2')['Really Different Var'], np.linspace(-5, 5, 20), label='Group 2', alpha=0.5);\n",
    "ax1.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "out_p_value = []\n",
    "for _ in range(200):\n",
    "    out_p_value += [ttest_ind(np.random.normal(loc=0, scale=1.0, size=(table_df.shape[0]//2)),\n",
    "          np.random.normal(loc=1, scale=1.0, size=(table_df.shape[0]//2))).pvalue]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "fig, m_axs = plt.subplots(2, 3, figsize=(20, 10))\n",
    "for c_ax, var_count in zip(m_axs.flatten(), np.linspace(1, 140, 9).astype(int)):\n",
    "    c_ax.hist(np.clip(np.array(out_p_value)*var_count, 0.01, 0.3), np.linspace(0.01, 0.3, 30))\n",
    "    c_ax.set_ylim(0, 100)\n",
    "    c_ax.set_title('p-value after multiple correction\\n for {} variables'.format(var_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "var_find_df = pd.DataFrame({'Variables': np.linspace(1, 100, 30).astype(int)})\n",
    "var_find_df['Likelihood of Detecting Really Different Variable'] = var_find_df['Variables'].map(\n",
    "    lambda var_count: np.mean(np.array(out_p_value)*var_count<0.05)\n",
    ")\n",
    "fig, ax1 = plt.subplots(1, 1, figsize=(15, 5))\n",
    "var_find_df.plot('Variables', 'Likelihood of Detecting Really Different Variable', ax=ax1)\n",
    "ax1.set_ylabel('% Likelihood');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Predicting and Validating - main categories\n",
    "\n",
    "<img src=\"../common/figures/MLalgorithms.png\" />\n",
    "\n",
    "Borrowed from http://peekaboo-vision.blogspot.ch/2013/01/machine-learning-cheat-sheet-for-scikit.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Overview\n",
    "\n",
    "\n",
    "Basically all of these are ultimately functions which map inputs to outputs. \n",
    "\n",
    "#### The input could be \n",
    "\n",
    "- an image\n",
    "- a point\n",
    "- a feature vector\n",
    "- or a multidimensional tensor\n",
    "\n",
    "#### The output is\n",
    "\n",
    "- a value (regression)\n",
    "- a classification (classification)\n",
    "- a group (clustering)\n",
    "- a vector / matrix / tensor with _fewer_ degrees of input / less noise as the original data (dimensionality reduction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Overfitting\n",
    "\n",
    "The most serious problem with machine learning and such approachs is overfitting your model to your data. Particularly as models get increasingly complex (random forest, neural networks, deep learning, ...), it becomes more and more difficult to apply common sense or even understand exactly what a model is doing and why a given answer is produced. \n",
    "\n",
    "```python\n",
    "magic_classifier = {}\n",
    "# training\n",
    "magic_classifier['Dog'] = 'Animal'\n",
    "magic_classifier['Bob'] = 'Person'\n",
    "magic_classifier['Fish'] = 'Animal'\n",
    "```\n",
    "\n",
    "Now use this classifier, on the training data it works really well\n",
    "\n",
    "```python\n",
    "magic_classifier['Dog'] == 'Animal' # true, 1/1 so far!\n",
    "magic_classifier['Bob'] == 'Person' # true, 2/2 still perfect!\n",
    "magic_classifier['Fish'] == 'Animal' # true, 3/3, wow!\n",
    "```\n",
    "\n",
    "On new data it doesn't work at all, it doesn't even execute.\n",
    "\n",
    "```python\n",
    "magic_classifier['Octopus'] == 'Animal' # exception?! but it was working so well\n",
    "magic_classifier['Dan'] == 'Person' # exception?! \n",
    "```\n",
    "\n",
    "The above example appeared to be a perfect trainer for mapping names to animals or people, but it just memorized the inputs and reproduced them at the output and so didn't actually learn anything, it just copied."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Validation\n",
    "\n",
    "\n",
    "Relevant for each of the categories, but applied in a slightly different way depending on the group. The idea is two divide the dataset into groups called training and validation or ideally training, validation, and testing. \n",
    "\n",
    "The analysis is then \n",
    "\n",
    "- developed on __training__\n",
    "- iteratively validated on __validation__\n",
    "- ultimately tested on __testing__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Concrete Example: Classifying Flowers\n",
    "\n",
    "\n",
    "Here we return to the iris data set and try to automatically classify flowers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "data = load_iris()\n",
    "iris_df = pd.DataFrame(data['data'], columns=data['feature_names'])\n",
    "iris_df['target'] = data['target_names'][data['target']]\n",
    "iris_df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Qualitative vs Quantitative\n",
    "\n",
    "Given the complexity of the tree, we need to do some pruning\n",
    "\n",
    "### Qualitative Assessment\n",
    " - Evaluating metrics using visual feedback\n",
    " - Compare with expectations from other independent techniques or approach\n",
    " - Are there artifacts which are included in the output?\n",
    " - Do the shapes look correct?\n",
    " - Are they distributed as expected?\n",
    " - Is their orientation meaningful?\n",
    " \n",
    "\n",
    "\n",
    "![Porosity](ext-figures/poros.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Quantitative Metrics\n",
    "\n",
    "\n",
    "With a quantitative approach, we can calculate \n",
    "- the specific shape \n",
    "- or distribution metrics on the sample \n",
    "\n",
    "with each parameter and establish the relationship between \n",
    "- parameter \n",
    "- and metric. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from graphviz import Digraph\n",
    "\n",
    "dot = Digraph()\n",
    "\n",
    "dot.node('Raw images',color='limegreen'),        dot.node('Gaussian filter', color='lightblue')\n",
    "dot.node('sigma=0.5', color='gray',shape='box'), dot.node('3x3 Neighbors', color='gray',shape='box')\n",
    "dot.node('Threshold', color='lightblue'),        dot.node('100', color='gray',shape='box')\n",
    "dot.node('Thickness analysis',color='hotpink'),  dot.node('Shape analysis',color='hotpink')\n",
    "dot.node('Input',color='limegreen'),        dot.node('Functions', color='lightblue')\n",
    "dot.node('Parameters', color='gray',shape='box'),dot.node('Output',color='hotpink')\n",
    "\n",
    "dot.edge('Raw images', 'Gaussian filter'),    dot.edge('sigma=0.5', 'Gaussian filter')\n",
    "dot.edge('3x3 Neighbors', 'Gaussian filter'), dot.edge('Gaussian filter','Threshold')\n",
    "dot.edge('Threshold', 'Thickness analysis'),  dot.edge('Threshold', 'Shape analysis')\n",
    "dot.edge('100','Threshold')\n",
    "dot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Parameter Sweep\n",
    "\n",
    "The way we do this is usually a parameter sweep which means \n",
    "- taking one (or more) parameters \n",
    "- and varying them between the reasonable bounds (judged qualitatively).\n",
    "\n",
    "<img src=\"../common/figures/parameter_sweep.png\" style=\"height:400px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Is it always the same?\n",
    "<table><tr><td>\n",
    "<img src=\"../common/figures/parameter_sweep_volume.png\" style=\"height:400px\"/></td>\n",
    "<td><img src=\"../common/figures/parameter_sweep_orientation.png\" style=\"height:400px\"/></td></tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Sensitivity\n",
    "\n",
    "### Control system theory\n",
    "Sensitivity is defined as \n",
    "- the change in the value of an output \n",
    "- against the change in the input.\n",
    "\n",
    "\n",
    "$$ S = \\frac{|\\Delta \\textrm{Metric}|}{|\\Delta \\textrm{Parameter}|} $$\n",
    "\n",
    "### Image processing\n",
    "Such a strict definition is not particularly useful for image processing since \n",
    "- a threshold has a unit of intensity and \n",
    "- a metric might be volume which has $m^3$ \n",
    "\n",
    "$\\rightarrow$ the sensitivity becomes volume per intensity!\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Practical Sensitivity\n",
    "\n",
    "A more common approach is to estimate the variation in this parameter between images or within a single image (automatic threshold methods can be useful for this) and define the sensitivity based on this variation.\n",
    "\n",
    "It is also common to normalize it with the mean value so the result is a percentage.\n",
    "\n",
    "$$ S = \\frac{max(\\textrm{Metric})-min(\\textrm{Metric})}{avg(\\textrm{Metric})} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Sensitivity: Real Measurements\n",
    "\n",
    "\n",
    "In this graph it is magnitude of the slope. The steeper the slope the more the metric changes given a small change in the parameter\n",
    "\n",
    "<img src=\"../common/figures/sensitivity_counts.png\" style=\"height:400px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Sensitivity: compare more than one variable\n",
    "Comparing Different Variables we see that \n",
    "- the best (lowest) value for the count sensitivity \n",
    "- is the highest for the volume and anisotropy. \n",
    "\n",
    "<img src=\"../common/figures/sensitivity_compare.png\" style=\"height:400px\"/>\n",
    "\n",
    "<center>\n",
    "    \n",
    "### A contradiction - Which metric is more important?\n",
    "\n",
    "</center>    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Reproducibility\n",
    "A very broad topic with plenty of sub-areas and deeper meanings. We mean two things by reproducibility\n",
    "\n",
    "### Analysis\n",
    "The process of going from images to numbers is detailed in a clear manner that __anyone__, __anywhere__ could follow and get the exact (within some tolerance) same numbers from your samples\n",
    "\n",
    "- No platform dependence\n",
    "- No proprietary or \"in house\" algorithms\n",
    "- No manual *clicking*, *tweaking*, or *copying*\n",
    "- One script to go from image to result\n",
    " \n",
    "\n",
    "\n",
    "### Measurement\n",
    "Everything for analysis + taking a measurement several times (noise and exact alignment vary each time) does not change the statistics _significantly_\n",
    "\n",
    "- No sensitivity to mounting or rotation\n",
    "- No sensitivity to noise\n",
    "- No dependence on exact illumination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Reproducible Analysis\n",
    "\n",
    "Since we will need to perform the same analysis many times to understand how reproducible it is.\n",
    "\n",
    "- Notebooks are good to develop and document analysis workflow.\n",
    "- The basis for reproducible analysis are scripts and macros. \n",
    "\n",
    "### With python scripts\n",
    "```python\n",
    "#!/$PYTHONPATH/python\n",
    "import sys\n",
    "from myAnalysis import analysisScript # some analysis script you implemented\n",
    "\n",
    "imageFile = sys.argv[0] # File name from command line\n",
    "\n",
    "threshold = 130\n",
    "analysisScript(fname=imageFile, threshold = threshold)\n",
    "```\n",
    "\n",
    "\n",
    "### or Matlab, ImageJ, or R\n",
    "```bash\n",
    "IMAGEFILE=$1\n",
    "THRESHOLD=130\n",
    "matlab -r \"inImage=$IMAGEFILE; threshImage=inImage>$THRESHOLD; analysisScript;\"\n",
    "```\n",
    "- __or__ \n",
    "```java -jar ij.jar -macro TestMacro.ijm blobs.tif```\n",
    "- __or__\n",
    "```Rscript -e \"library(plyr);...\"```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Some software engineering - Unit testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Unit Testing\n",
    "\n",
    "In computer programming, unit testing is a method by which individual units of source code, sets of one or more computer program modules together with associated control data, usage procedures, and operating procedures, are tested to determine if they are fit for use.\n",
    "\n",
    "- Intuitively, one can view a unit as the smallest testable part of an application\n",
    "- Unit testing is possible with every language\n",
    "- Most (Java, C++, Matlab, R, Python) have built in support for automated testing and reporting\n",
    "\n",
    "[Comoutational science: ... Error](http://doi.org/10.1038/467775a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Unit Testing - design\n",
    "The first requirement for unit testing to work well is to have your code divided up into small independent parts (functions)\n",
    "### What to test\n",
    "- Each part can then be tested independently (unit testing)\n",
    "    - If the tests are well done, units can be changed and tested independently\n",
    "    - Makes upgrading or expanding tools _easy_\n",
    "- The entire path can be tested (integration testing)\n",
    "    - Catches mistakes in integration or _glue_\n",
    "\n",
    "### How to test\n",
    "- The _happy path_ - check what it is supposed to do\n",
    "- To __provoke__ your code - provide data that will fail execution\n",
    "\n",
    "### Test data\n",
    "Ideally with realistic but simulated test data\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "<center>The utility of the testing is only as good as the tests you make</center>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Example\n",
    "Given the following function\n",
    "```function vxCnt=countVoxs(inImage)```\n",
    "\n",
    "We can write the following tests:\n",
    "\n",
    "#### _testEmpty2d_ \n",
    "```assert countVoxs(zeros(3,3)) == 0```\n",
    "\n",
    "#### testEmpty3d\n",
    "```assert countVoxs(zeros(3,3,3)) == 0```\n",
    "\n",
    "#### testDiag3d\n",
    "```assert countVoxs(eye(3)) == 3```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Unit Testing: Example\n",
    "Given the following function\n",
    "```function shapeTable=shapeAnalysis(inImage)```\n",
    "\n",
    "We should decompose the function into sub-components with single tasks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphviz import Digraph\n",
    "dot = Digraph()\n",
    "dot.edge('shapeAnalysis(inImage)', 'componentLabel(inImage)'), dot.edge('shapeAnalysis(inImage)', 'analyzeObject(inObject)')\n",
    "dot.edge('analyzeObject(inObject)','countVoxs(inObject)'),     dot.edge('analyzeObject(inObject)','calculateCOV(inObject)')\n",
    "dot.edge('analyzeObject(inObject)','calcShapeT(covMat)'),      dot.edge('analyzeObject(inObject)','calcOrientation(shapeT)')\n",
    "dot.edge('analyzeObject(inObject)','calcAnisotropy(shapeT)')\n",
    "dot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Unit Testing in Python\n",
    "\n",
    "## PyTest\n",
    "Packages like PyTest are \n",
    "- well suited for larger projects \n",
    "- you make a set of specific tests for each module \n",
    "- run each time the project is updated. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Unit testing examples from Scikit Image\n",
    "https://github.com/scikit-image/scikit-image/tree/master/skimage\n",
    "\n",
    "- Test Watershed https://github.com/scikit-image/scikit-image/blob/16d3fd07e7d882d7f6b74e8dc4028ff946ac7e63/skimage/morphology/tests/test_watershed.py#L79\n",
    "\n",
    "- Test Connected Components https://github.com/scikit-image/scikit-image/blob/16d3fd07e7d882d7f6b74e8dc4028ff946ac7e63/skimage/morphology/tests/test_ccomp.py#L13\n",
    "\n",
    "```python\n",
    "class TestWatershed(unittest.TestCase):\n",
    "    eight = np.ones((3, 3), bool)\n",
    "\n",
    "    def test_watershed01(self):\n",
    "        \"watershed 1\"\n",
    "        data = np.array([[0, 0, 0, 0, 0, 0, 0],\n",
    "                            [0, 0, 0, 0, 0, 0, 0],\n",
    "                            [0, 0, 0, 0, 0, 0, 0],\n",
    "                               [0, 1, 1, 1, 1, 1, 0],\n",
    "                               [0, 1, 0, 0, 0, 1, 0],\n",
    "                               [0, 1, 0, 0, 0, 1, 0],\n",
    "                               [0, 1, 0, 0, 0, 1, 0],\n",
    "                               [0, 1, 1, 1, 1, 1, 0],\n",
    "                               [0, 0, 0, 0, 0, 0, 0],\n",
    "                               [0, 0, 0, 0, 0, 0, 0]], np.uint8)\n",
    "        markers = np.array([[ -1, 0, 0, 0, 0, 0, 0],\n",
    "                               [0, 0, 0, 0, 0, 0, 0],\n",
    "                               [0, 0, 0, 0, 0, 0, 0],\n",
    "                                  [  0, 0, 0, 0, 0, 0, 0],\n",
    "                                  [  0, 0, 0, 0, 0, 0, 0],\n",
    "                                  [  0, 0, 0, 1, 0, 0, 0],\n",
    "                                  [  0, 0, 0, 0, 0, 0, 0],\n",
    "                                  [  0, 0, 0, 0, 0, 0, 0],\n",
    "                                  [  0, 0, 0, 0, 0, 0, 0],\n",
    "                                  [  0, 0, 0, 0, 0, 0, 0]],\n",
    "                                 np.int8)\n",
    "        out = watershed(data, markers, self.eight)\n",
    "        expected = np.array([[-1, -1, -1, -1, -1, -1, -1],\n",
    "                      [-1, -1, -1, -1, -1, -1, -1],\n",
    "                      [-1, -1, -1, -1, -1, -1, -1],\n",
    "                      [-1,  1,  1,  1,  1,  1, -1],\n",
    "                      [-1,  1,  1,  1,  1,  1, -1],\n",
    "                      [-1,  1,  1,  1,  1,  1, -1],\n",
    "                      [-1,  1,  1,  1,  1,  1, -1],\n",
    "                      [-1,  1,  1,  1,  1,  1, -1],\n",
    "                      [-1, -1, -1, -1, -1, -1, -1],\n",
    "                      [-1, -1, -1, -1, -1, -1, -1]])\n",
    "        error = diff(expected, out)\n",
    "        assert error < eps\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## DocTests\n",
    "\n",
    "Keep the tests in the code itself: https://github.com/scikit-image/scikit-image/blob/16d3fd07e7d882d7f6b74e8dc4028ff946ac7e63/skimage/filters/thresholding.py#L886\n",
    "```python\n",
    "def apply_hysteresis_threshold(image, low, high):\n",
    "    \"\"\"Apply hysteresis thresholding to `image`.\n",
    "    This algorithm finds regions where `image` is greater than `high`\n",
    "    OR `image` is greater than `low` *and* that region is connected to\n",
    "    a region greater than `high`.\n",
    "    Parameters\n",
    "    ----------\n",
    "    image : array, shape (M,[ N, ..., P])\n",
    "        Grayscale input image.\n",
    "    low : float, or array of same shape as `image`\n",
    "        Lower threshold.\n",
    "    high : float, or array of same shape as `image`\n",
    "        Higher threshold.\n",
    "    Returns\n",
    "    -------\n",
    "    thresholded : array of bool, same shape as `image`\n",
    "        Array in which `True` indicates the locations where `image`\n",
    "        was above the hysteresis threshold.\n",
    "    Examples\n",
    "    --------\n",
    "    >>> image = np.array([1, 2, 3, 2, 1, 2, 1, 3, 2])\n",
    "    >>> apply_hysteresis_threshold(image, 1.5, 2.5).astype(int)\n",
    "    array([0, 1, 1, 1, 0, 0, 0, 1, 1])\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] J. Canny. A computational approach to edge detection.\n",
    "           IEEE Transactions on Pattern Analysis and Machine Intelligence.\n",
    "           1986; vol. 8, pp.679-698.\n",
    "           DOI: 10.1109/TPAMI.1986.4767851\n",
    "    \"\"\"\n",
    "    low = np.clip(low, a_min=None, a_max=high)  # ensure low always below high\n",
    "    mask_low = image > low\n",
    "    mask_high = image > high\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Unit Testing Jupyter\n",
    "Working primarily in notebooks makes regular testing more difficult but not impossible. If we employ a few simple tricks we can use doctesting seamlessly inside of Jupyter. We can make what in python is called an annotatation to setup this code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import doctest\n",
    "import copy\n",
    "import functools\n",
    "\n",
    "def autotest(func):\n",
    "    globs = copy.copy(globals())\n",
    "    globs.update({func.__name__: func})\n",
    "    doctest.run_docstring_examples(\n",
    "        func, globs, verbose=True, name=func.__name__)\n",
    "    return func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "format": "column",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "@autotest\n",
    "def add_5(x):\n",
    "    \"\"\"\n",
    "    Function adds 5\n",
    "    >>> add_5(5)\n",
    "    10\n",
    "    \"\"\"\n",
    "    return x+5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "format": "column",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from skimage.measure import label\n",
    "import numpy as np\n",
    "@autotest\n",
    "def simple_label(x):\n",
    "    \"\"\"\n",
    "    Label an image\n",
    "    >>> test_img = np.eye(3)\n",
    "    >>> test_img\n",
    "    array([[1., 0., 0.],\n",
    "           [0., 1., 0.],\n",
    "           [0., 0., 1.]])\n",
    "    >>> simple_label(test_img)\n",
    "    array([[1, 0, 0],\n",
    "           [0, 1, 0],\n",
    "           [0, 0, 1]])\n",
    "    >>> test_img[1,1] = 0\n",
    "    >>> simple_label(test_img)\n",
    "    array([[1, 0, 0],\n",
    "           [0, 0, 0],\n",
    "           [0, 0, 2]])\n",
    "    \"\"\"\n",
    "    return label(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Unit Testing Matlab\n",
    "https://www.mathworks.com/help/matlab/matlab-unit-test-framework.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Test Driven Programming\n",
    "\n",
    "\n",
    "Test Driven programming is a style or approach to programming where the tests are written before the functional code. Like very concrete specifications. It is easy to estimate how much time is left since you can automatically see how many of the tests have been passed. You and your collaborators are clear on the utility of the system.\n",
    "\n",
    "1. shapeAnalysis must give an anisotropy of 0 when we input a sphere\n",
    "1. shapeAnalysis must give the center of volume within 0.5 pixels\n",
    "1. shapeAnalysis must run on a 1000x1000 image in 30 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Continuous Integration\n",
    "Conntinuous integration is the process of running tests automatically everytime changes are made. This is possible to setup inside of many IDEs and is offered as a commercial service from companies like CircleCI and Travis. We use them for the QBI course to make sure all of the code in the slides are correct. Projects like scikit-image use them to ensure changes that are made do not break existing code without requiring manual checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Presenting the results - bringing out the message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Visualization\n",
    "\n",
    "\n",
    "One of the biggest problems with _big_ sciences is trying to visualize a lot of heterogeneous data. \n",
    "\n",
    "- Tables are difficult to interpret\n",
    "- 3D Visualizations are very difficult to compare visually \n",
    "- Contradictory necessity of simple single value results and all of the data to look for trends and find problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Purpose of the visualization\n",
    "\n",
    "You visualize your data for different reasons:\n",
    "### Understanding and exploration \n",
    "- Small and known audience (you and colleagues)\n",
    "- High degree of understanding of specific topic.\n",
    "    \n",
    "### Presenting your results\n",
    "- Wider and sometimes unknown audience (reader of paper, person listening to presentation)\n",
    "- At best general understanding of the topic.\n",
    "    \n",
    "<img src=\"../common/figures/Knaflic_audience.png\" style='height:300px'/> from [Knaflic 2015](https://doi.org/10.1002/9781119055259)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Bad Graphs\n",
    "\n",
    "There are too many graphs which say:\n",
    "\n",
    "- *my data is very complicated*\n",
    "- *I know how to use __ toolbox in Matlab/R/Mathematica*\n",
    "- Most programs by default make poor plots\n",
    "- Good visualizations takes time to produce\n",
    "\n",
    "<table>\n",
    "    <tr><td><img src='ext-figures/badImage1.png' style='height:300px'/></td><td><img src='ext-figures/badPlot4.png' style='height:300px' /></td><td><img src='ext-figures/badImage3.png' style='height:300px' /></td><td><img src='ext-figures/badImage2.png' style='height:300px' /></td></tr></table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# How to improve - Key Ideas \n",
    "\n",
    "\n",
    "1. What is my message? \n",
    "1. Does the graphic communicate it clearly?\n",
    "1. Is a graphic representation really necessary?\n",
    " - Does every line / color serve a purpose?\n",
    " - Pretend ink is very expensive\n",
    "\n",
    "#### Some literature\n",
    "- [Few, Should data visualization always be beautiful?, 2012](https://www.perceptualedge.com/blog/?p=1169)\n",
    "\n",
    "- [Knaflic, Storytelling with Data: A Data Visualization Guide for Business Professionals, 2015](https://doi.org/10.1002/9781119055259)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Simple Rules\n",
    "\n",
    "1. Never use 3D graphics when it can be avoided (unless you want to be deliberately misleading)\n",
    "![Dumb 3d](ext-figures/3dplot.png)\n",
    "1. Pie charts can also be hard to interpret\n",
    "1. Background color should almost always be white (not light gray)\n",
    "1. Use color palettes adapted to human visual sensitivity \n",
    "1. Use colors and transparency smart\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# What is my message\n",
    "Plots to \"show the results\" or \"get a feeling\" are usually not good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotnine import *\n",
    "from plotnine.data import *\n",
    "import pandas as pd\n",
    "# Some data\n",
    "xd = np.random.rand(80)\n",
    "yd = xd + np.random.rand(80)\n",
    "zd = np.random.rand(80)\n",
    "\n",
    "df = pd.DataFrame(dict(x=xd,y=yd,z=zd))\n",
    "ggplot(df,aes(x='x',y='y')) + geom_point()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Focus on a single, simple message\n",
    "\"X is a little bit correlated with Y\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "(ggplot(df,aes(x='x',y='y')) \n",
    " + geom_point() \n",
    " + geom_smooth(method=\"lm\")\n",
    "# + coord_equal() \n",
    " + labs(title=\"X is weakly correlated with Y\")\n",
    " + theme_bw(20) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Does my graphic communicate it clearly?\n",
    "\n",
    "Too much data makes it very difficult to derive a clear message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xd = np.random.rand(5000)\n",
    "yd = (xd-0.5)*np.random.rand(5000)\n",
    "\n",
    "df = pd.DataFrame(dict(x=xd,y=yd))\n",
    "(ggplot(df,aes(x='x',y='y')) \n",
    " + geom_point()\n",
    " + geom_point()\n",
    " + coord_equal()\n",
    " + theme_bw(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Reduce the data\n",
    "Filter and reduce information until it is extremely simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "(ggplot(df,aes(x='x',y='y'))\n",
    " + stat_bin2d(bins=30)\n",
    " + geom_smooth(method=\"lm\",color='red')\n",
    " + coord_equal()\n",
    " + theme_bw(20)\n",
    " + guides(color='F')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Reduce even further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "(ggplot(df,aes(x='x',y='y'))\n",
    "  + geom_density_2d(aes(x='x', y='y', color='..level..'))\n",
    "  + geom_smooth(method=\"lm\")\n",
    "  + coord_equal() \n",
    "  + labs(color=\"Type\")\n",
    "  + theme_bw(15)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Grammar of Graphics\n",
    "\n",
    "\n",
    "### What is a grammar?\n",
    "- Set of rules for constructing and validating a sentence\n",
    "- Specifies the relationship and order between the words constituting the sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## How does grammar apply to graphics?\n",
    "If we develop a consistent way of \n",
    "- expressing graphics (sentences) \n",
    "- in terms of elements (words) \n",
    "we can compose and decompose graphics easily\n",
    "\n",
    "\n",
    "The most important modern work in graphical grammars is [\"The Grammar of Graphics\"](https://doi.org/10.1007/0-387-28695-0)  by Wilkinson, Anand, and Grossman (2005). \n",
    "\n",
    "This work built on earlier work by Bertin (1983) and proposed a grammar that can be used to describe and construct a wide range of statistical graphics.\n",
    "\n",
    "\n",
    "\n",
    "#### Graphics in python\n",
    "- Graphical grammar can be applied in [R using the ggplot2 library](https://doi.org/10.1007/978-3-319-24277-4), which is ported to [python](https://www.datascienceworkshops.com/blog/plotnine-grammar-of-graphics-for-python).\n",
    "- Matplotlib does not support grammar but is still very useful:\n",
    "[Matplotlib 3.0 Cookbook](https://www.packtpub.com/big-data-and-business-intelligence/matplotlib-30-cookbook) [ETHZ lib](https://learning.oreilly.com/library/view/matplotlib-30-cookbook/9781789135718), [code examples](https://github.com/PacktPublishing/Matplotlib-3.0-Cookbook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Grammar Explained\n",
    "\n",
    "Normally we think of plots in terms of some sort of data which is fed into a plot command that produces a picture\n",
    "- In Excel you select a range and plot-type and click \"Make\"\n",
    "- In Matlab you run ```plot(xdata,ydata,color/shape)``` \n",
    "\n",
    "1. These produces entire graphics (sentences) or at least phrases in one go and thus abstract away from the idea of grammar. \n",
    "1. If you spoke by finding entire sentences in a book it would be very ineffective, it is much better to build up word by word\n",
    "\n",
    "<img src=\"../common/figures/niceplot.svg\" style=\"height:200px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Grammar\n",
    "\n",
    "Separate the graph into its component parts\n",
    "\n",
    "<table>\n",
    "<col width=\"300px\" />\n",
    "<tr><th>Data mapping</th><th>Points</th><th>Axes/Coordinate system</th><th>Labels/annotation</th></tr>\n",
    "<tr>\n",
    "<td>$var1 \\rightarrow x$, $var2 \\rightarrow y$</td>\n",
    "<td><img src=\"../common/figures/niceplot_points.png\" style=\"height:300px\"></td>\n",
    "<td><img src=\"../common/figures/niceplot_axes.png\"   style=\"height:300px\"></td>\n",
    "<td><img src=\"../common/figures/niceplot_annotations.png\" style=\"height:300px\"></td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "Construct graphics by focusing on each portion independently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Wrapping up\n",
    "\n",
    "\n",
    "- I am not a statistician\n",
    "- This is not a statistics course\n",
    "- If you have questions or concerns\n",
    " - Both ETHZ and Uni Zurich offer __free__ consultation with real statisticians\n",
    " - They are rarely bearers of good news\n",
    " \n",
    "- Simulations (even simple ones) are very helpful \n",
    "- Try and understand the tests you are performing\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "# Old slides to transfer from R to python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "[old lecture 2017](https://rawgit.com/Quantitative-Big-Imaging/Quantitative-Big-Imaging-2017/master/Lectures/08-Slides.html#(53))\n",
    "[old lecture 2019](https://github.com/kmader/Quantitative-Big-Imaging-2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Old parameter sweep figure, needs translation from R\n",
    "import sys\n",
    "sys.path.append(\"../common/scripts/\")\n",
    "import shapeAnalysisProcess\n",
    "import commonReportFunctions\n",
    "\n",
    "# read and correct the coordinate system\n",
    "def threshfun(x) :\n",
    "  pth = rev(strsplit(x,\"/\")[[1]])[2]\n",
    "  t=strsplit(pth,\"_\")[[1]][3]\n",
    "  # as.numeric(substring(t,2,nchar(t)))\n",
    "\n",
    "def readfcn(x) :\n",
    "    cbind(compare.foam.corrected(x,checkProj=F),thresh=thresh.fun(x))\n",
    "    # Where are the csv files located\n",
    "    rootDir=\"../common/data/mcastudy\" \n",
    "    clpor.files=Sys.glob(paste(rootDir,\"/a*/lacun_0.csv\",sep=\"/\")) # list all of the files\n",
    "    data = ldply(clpor.files,readfcn,.parallel=T) # Read in all of the files\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    return df;\n",
    "\n",
    "lacun=readfcn(10)\n",
    "\n",
    "(ggplot(lacun,aes(y=VOLUME*1e9,x=thresh))\n",
    "+ geom_jitter(alpha=0.1)+geom_smooth()\n",
    "+ theme_bw(24)\n",
    "+ labs(y=\"Volume (um3)\",x=\"Threshold Value\",color=\"Threshold\")\n",
    "+ ylim(0,1000))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "(ggplot(subset(lacun,thresh %% 1000==0),aes(y=VOLUME*1e9,x=as.factor(thresh)))\n",
    "    + geom_violin()\n",
    "    + theme_bw(24)\n",
    "    + labs(y=\"Volume (um3)\",x=\"Threshold Value\",color=\"Threshold\")\n",
    "    + ylim(0,1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "(ggplot(lacun,aes(y=PCA1_Z,x=thresh))+\n",
    "    + geom_jitter(alpha=0.1)+geom_smooth()+\n",
    "    + theme_bw(24)\n",
    "    + labs(y=\"Orientation\",x=\"Threshold Value\",color=\"Threshold\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "# Sensitivity: Real Measurements\n",
    "\n",
    "\n",
    "In this graph it is magnitude of the slope. The steeper the slope the more the metric changes given a small change in the parameter\n",
    "\n",
    "```{r , fig.height=5}\n",
    "poresum<-function(all.data) ddply(all.data,.(thresh),function(c.sample) {\n",
    "  data.frame(Count=nrow(c.sample),\n",
    "             Volume=mean(c.sample$VOLUME*1e9),\n",
    "             Stretch=mean(c.sample$AISO),\n",
    "             Oblateness=mean(c.sample$OBLATENESS),\n",
    "             #Lacuna_Density_mm=1/mean(c.sample$DENSITY_CNT),\n",
    "             Length=mean(c.sample$PROJ_PCA1*1000),\n",
    "             Width=mean(c.sample$PROJ_PCA2*1000),\n",
    "             Height=mean(c.sample$PROJ_PCA3*1000),\n",
    "             Orientation=mean(abs(c.sample$PCA1_Z)))\n",
    "})\n",
    "comb.summary<-cbind(poresum(all.lacun),Phase=\"Lacuna\")\n",
    "splot<-ggplot(comb.summary,aes(x=thresh))\n",
    "splot+geom_line(aes(y=Count))+geom_point(aes(y=Count))+scale_y_log10()+\n",
    "  theme_bw(24)+labs(y=\"Object Count\",x=\"Threshold\",color=\"Phase\")\n",
    "```\n",
    "\n",
    "Comparing Different Variables we see that the best (lowest) value for the count sensitivity is the highest for the volume and anisotropy. \n",
    "\n",
    "```{r , fig.height=5}\n",
    "calc.sens<-function(in.df) {\n",
    "  data.frame(sens.cnt=100*with(in.df,(max(Count)-min(Count))/mean(Count)),\n",
    "             sens.vol=100*with(in.df,(max(Volume)-min(Volume))/mean(Volume)),\n",
    "             sens.stretch=100*with(in.df,(max(Stretch)-min(Stretch))/mean(Stretch))\n",
    "             )\n",
    "}\n",
    "sens.summary<-ddply.cutcols(comb.summary,.(cut_interval(thresh,5)),calc.sens)\n",
    "ggplot(sens.summary,aes(x=thresh))+\n",
    "  geom_line(aes(y=sens.cnt,color=\"Count\"))+\n",
    "  geom_line(aes(y=sens.vol,color=\"Volume\"))+\n",
    "  geom_line(aes(y=sens.stretch,color=\"Anisotropy\"))+\n",
    "  labs(x=\"Threshold\",y=\"Sensitivity (%)\",color=\"Metric\")+\n",
    "  theme_bw(20)\n",
    "```\n",
    "\n",
    "### Which metric is more important?"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "rise": {
   "autolaunch": true,
   "enable_chalkboard": true,
   "footer": "April 16, 2020 - ETH 227-0966-00L: Quantitative Big Imaging/Statistics and reproducibility",
   "header": "<table width='100%' style='margin: 0px;'><tr><td align='left'><img src='../common/figures/eth_logo_kurz_pos.svg' style='height:30px;'></td><td align='right'><img src='../common/figures/PSI-Logo.svg' style='height:50px;'></td></tr></table>",
   "scroll": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
