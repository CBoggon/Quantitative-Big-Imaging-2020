{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# ETHZ: 227-0966-00L\n",
    "# Quantitative Big Imaging\n",
    "# March 14, 2019\n",
    "\n",
    "## Basic Segmentation and Discrete Binary Structures\n",
    "### Part 2\n",
    "\n",
    "### Anders Kaestner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# A Machine Learning Approach to Image Processing\n",
    "\n",
    "Segmentation and all the steps leading up to it are really a specialized type of learning problem. \n",
    "\n",
    "Let's look at an important problem for electron microscopy imaging..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.io import imread\n",
    "%matplotlib inline\n",
    "cell_img = (255-imread(\"../common/data/em_image.png\")[::2, ::2])/255.0\n",
    "cell_seg = rgb2gray(imread(\"../common/data/em_image_seg.png\"))[::2, ::2]>0\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 4), dpi=150)\n",
    "ax1.imshow(cell_img, cmap='gray')\n",
    "ax2.imshow(cell_seg, cmap='hot')\n",
    "ax1.axis('off')\n",
    "ax2.axis('off')\n",
    "ax1.set_title('Image')\n",
    "ax2.set_title('Mitochondria');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We want to identify which class each pixel belongs to.\n",
    "What does identify mean?\n",
    "- Classify the pixels in a mitochondria as _Foreground_\n",
    "- Classify the pixels outside of a mitochondria as _Background_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# How do we quantify this?\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "    \n",
    "- __True Positive__ values in the mitochondria that are classified as _Foreground_\n",
    "- __True Negative__ values outside the mitochondria that are classified as _Background_\n",
    "\n",
    "</div>\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "    \n",
    "- __False Positive__ values outside the mitochondria that are classified as _Foreground_\n",
    "- __False Negative__ values in the mitochondria that are classified as _Background_\n",
    "\n",
    "</div>\n",
    "We can then apply a threshold to the image to determine the number of points in each category\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(12, 4), dpi=150)\n",
    "ax1.imshow(cell_img, cmap='gray')\n",
    "thresh_img = cell_img > 0.52\n",
    "ax2.imshow(thresh_img, cmap='hot')\n",
    "ax3.imshow(cell_seg, cmap='hot')\n",
    "ax1.axis('off')\n",
    "ax2.axis('off')\n",
    "ax3.axis('off')\n",
    "ax1.set_title('Image')\n",
    "ax2.set_title('Threshold')\n",
    "ax3.set_title('Mitochondria Labels');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def tp_func(real_img_idx, pred_img_idx):\n",
    "    if real_img_idx == 1 and pred_img_idx == 1:\n",
    "        return 'True Positive','green'\n",
    "    if real_img_idx == 0 and pred_img_idx == 0:\n",
    "        return 'True Negative','green'\n",
    "    if real_img_idx == 0 and pred_img_idx == 1:\n",
    "        return 'False Positive','red'\n",
    "    if real_img_idx == 1 and pred_img_idx == 0:\n",
    "        return 'False Negative','red'\n",
    "\n",
    "\n",
    "out_results = {}\n",
    "fig, m_ax = plt.subplots(2, 2, figsize=(8, 6), dpi=150)\n",
    "for real_img_idx, n_ax in zip([0, 1], m_ax):\n",
    "    for pred_img_idx, c_ax in zip([0, 1], n_ax):\n",
    "        match_img = (thresh_img == pred_img_idx) & (cell_seg == real_img_idx)\n",
    "        (tp_title,color) = tp_func(real_img_idx, pred_img_idx)\n",
    "        c_ax.matshow(match_img, cmap='hot')\n",
    "        out_results[tp_title] = np.sum(match_img)\n",
    "        c_ax.set_title(tp_title,color=color)\n",
    "        c_ax.axis('off')\n",
    "print(out_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Apply Precision and Recall\n",
    "\n",
    "\n",
    "- __Recall__ (sensitivity) = $TP/(TP+FN)$\n",
    "- __Precision__            = $TP/(TP+FP)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print('Recall: %2.2f' % (out_results['True Positive'] /\n",
    "                         (out_results['True Positive']+out_results['False Negative'])))\n",
    "print('Precision: %2.2f' % (out_results['True Positive'] /\n",
    "                            (out_results['True Positive']+out_results['False Positive'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "[Confusion matrix](https://towardsdatascience.com/understanding-confusion-matrix-a9ad42dcfd62)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "### [ROC Curve](https://en.wikipedia.org/wiki/Receiver_operating_characteristic)\n",
    "Reciever Operating Characteristic ([first developed for WW2 soldiers detecting objects in battlefields using radar](https://en.wikipedia.org/wiki/Receiver_operating_characteristic#History)). \n",
    "\n",
    "The ideal is the top-right (identify everything and miss nothing). \n",
    "\n",
    "As we saw before, for a single threshold value 0.5, we were able to compute a single recall and precision. \n",
    "\n",
    "If we want to make an ROC curve we take a number of threshold values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import OrderedDict\n",
    "\n",
    "out_vals = []\n",
    "for thresh_val in np.linspace(0.1, 0.9):\n",
    "    thresh_img = cell_img > thresh_val\n",
    "    for real_img_idx in [0, 1]:\n",
    "        for pred_img_idx in [0, 1]:\n",
    "            match_img = (thresh_img == pred_img_idx) & (\n",
    "                cell_seg == real_img_idx)\n",
    "            tp_title = tp_func(real_img_idx, pred_img_idx)\n",
    "            out_results[tp_title] = np.sum(match_img)\n",
    "    out_vals += [\n",
    "        OrderedDict(\n",
    "            Threshold=thresh_val,\n",
    "            Recall=out_results['True Positive'] /\n",
    "            (out_results['True Positive']+out_results['False Negative']),\n",
    "            Precision=(out_results['True Positive'] /\n",
    "                       (out_results['True Positive']+out_results['False Positive'])),\n",
    "            False_Positive_Rate=(out_results['False Positive'] /\n",
    "                       (out_results['False Positive']+out_results['True Negative'])),\n",
    "            **out_results\n",
    "        )]\n",
    "\n",
    "roc_df = pd.DataFrame(out_vals)\n",
    "roc_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Making ROC Curves Easier\n",
    "ROC curves are a very common tool for analyzing the performance of binary classification systems and there are a large number of tools which can automatically make them. Here we show how it is done with scikit-image. \n",
    "\n",
    "Another way of showing the ROC curve (more common for machine learning rather than medical diagnosis) is using the True positive rate and False positive rate\n",
    "\n",
    "- __True Positive Rate__ (recall)= $TP/(TP+FN)$\n",
    "- __False Positive Rate__ = $FP/(FP+TN)$\n",
    "\n",
    "These show very similar information with the major difference being the goal is to be in the upper left-hand corner. Additionally random guesses can be shown as the slope 1 line. Therefore for a system to be useful it must lie above the random line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(1, 1, dpi=200)\n",
    "ax1.plot(roc_df['False_Positive_Rate'], roc_df['Recall']  , 'b.-', label='ROC Curve')\n",
    "ax1.plot(0, 1.0, 'r+', markersize=20, label='Ideal')\n",
    "ax1.set_xlim(0, 1.1)\n",
    "ax1.set_ylim(0, 1.1)\n",
    "ax1.set_ylabel('True Positive Rate / Recall')\n",
    "ax1.set_xlabel('False Positive Rate')\n",
    "ax1.legend(loc=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "fpr, tpr, thresholds = roc_curve(cell_seg.ravel().astype(int),\n",
    "                                 cell_img.ravel())\n",
    "\n",
    "fig, ax1 = plt.subplots(1, 1, dpi=200)\n",
    "ax1.plot(fpr, tpr, 'b.-', markersize=0.01,  label='ROC Curve')\n",
    "ax1.plot(0.0, 1.0, 'r+', markersize=20, label='Ideal')\n",
    "ax1.plot([0, 1], [0, 1], 'g-', label='Random Guessing')\n",
    "ax1.set_xlim(-0.1, 1.1)\n",
    "ax1.set_ylim(-0.1, 1.1)\n",
    "ax1.set_xlabel('False Positive Rate')\n",
    "ax1.set_ylabel('True Positive Rate')\n",
    "ax1.legend(loc=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from skimage.filters import gaussian, median\n",
    "\n",
    "\n",
    "def no_filter(x):\n",
    "    return x\n",
    "\n",
    "\n",
    "def gaussian_filter(x):\n",
    "    return gaussian(x, sigma=2)\n",
    "\n",
    "\n",
    "def diff_of_gaussian_filter(x):\n",
    "    return gaussian(x, sigma=1)-gaussian(x, sigma=3)\n",
    "\n",
    "\n",
    "def median_filter(x):\n",
    "    return median(x, np.ones((3, 3)))\n",
    "\n",
    "\n",
    "fig, m_axs = plt.subplots(1, 5, figsize=(15, 3), dpi=200)\n",
    "m_axs[0].imshow(cell_seg, cmap='gray')\n",
    "for c_filt, c_ax in zip([no_filter, gaussian_filter, diff_of_gaussian_filter, median_filter], m_axs[1:]):\n",
    "    c_ax.imshow(c_filt(cell_img), cmap='bone')\n",
    "    c_ax.set_title(c_filt.__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(1, 1, dpi=200)\n",
    "for c_filt in [no_filter, gaussian_filter, diff_of_gaussian_filter, median_filter]:\n",
    "    fpr, tpr, thresholds = roc_curve(cell_seg.ravel().astype(int),\n",
    "                                     c_filt(cell_img).ravel())\n",
    "    ax1.plot(fpr, tpr, '-', markersize=0.01,\n",
    "             label='ROC Curve ({})'.format(c_filt.__name__))\n",
    "\n",
    "ax1.plot(0.0, 1.0, 'r+', markersize=20, label='Ideal')\n",
    "ax1.plot([0, 1], [0, 1], 'k-', label='Random Guessing')\n",
    "ax1.set_xlim(-0.1, 1.1)\n",
    "ax1.set_ylim(-0.1, 1.1)\n",
    "ax1.set_xlabel('False Positive Rate')\n",
    "ax1.set_ylabel('True Positive Rate')\n",
    "ax1.legend(loc=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We can then use this ROC curve to compare different filters (or even entire workflows), if the area is higher the approach is better.\n",
    "\n",
    "Different approaches can be compared by area under the curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "for c_filt in [no_filter, gaussian_filter, diff_of_gaussian_filter, median_filter]:\n",
    "    print('%s - %2.2f' % (c_filt.__name__, roc_auc_score(cell_seg.ravel().astype(int),\n",
    "                                                         c_filt(cell_img).ravel())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Evaluating Models\n",
    "\n",
    "- https://github.com/jvns/talks/blob/master/pydatanyc2014/slides.md\n",
    "- http://mathbabe.org/2012/03/06/the-value-added-teacher-model-sucks/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Multiple Phases: Segmenting Shale\n",
    "\n",
    "- Shale provided from Kanitpanyacharoen, W. (2012). Synchrotron X-ray Applications Toward an Understanding of Elastic Anisotropy.\n",
    "\n",
    "- Here we have a shale sample measured with X-ray tomography with three different phases inside (clay, rock, and air).\n",
    "- The model is that because the chemical composition and density of each phase is different they will absorb different amounts of x-rays and appear as different brightnesses in the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.io import imread\n",
    "%matplotlib inline\n",
    "shale_img = imread(\"ext-figures/ShaleSample.jpg\")/255.0\n",
    "fig, ax1 = plt.subplots(1, 1, dpi=200)\n",
    "ax1.imshow(shale_img, cmap='bone')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Ideally we would derive 3 values for the thresholds based on a model for the composition of each phase and how much it absorbs, but that is not always possible or practical.\n",
    "- While there are 3 phases clearly visible in the image, the histogram is less telling (even after being re-scaled)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "plt.hist(shale_img.ravel(), 100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Multiple Segmentations\n",
    "\n",
    "For this exercise we choose arbitrarily 3 ranges for the different phases and perform visual inspection\n",
    "\n",
    "The relation can explicitly be written out as\n",
    "$$ I(x) = \n",
    "\\begin{cases}\n",
    "\\text{Void}, & 0 \\leq x \\leq 0.3  \\\\\n",
    "\\text{Clay}, & 0.3 < x \\leq 0.5 \\\\\n",
    "\\text{Rock}, & 0.5 < x\n",
    "\\end{cases}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "fig, m_axs = plt.subplots(1, 4, dpi=200, figsize=(6, 3))\n",
    "m_axs[0].imshow(shale_img, cmap='bone')\n",
    "m_axs[0].set_title('Shale Image')\n",
    "used_vox = np.zeros_like(shale_img).astype(np.uint8)\n",
    "for c_ax, c_max, c_title in zip(m_axs[1:], [0.3, 0.5, 1.0], ['Void', 'Clay', 'Rock']):\n",
    "    c_slice = (shale_img < c_max)-used_vox\n",
    "    c_ax.matshow(c_slice, cmap='bone')\n",
    "    used_vox += c_slice\n",
    "    c_ax.axis('off')\n",
    "    c_ax.set_title('%s\\n$x<%2.2f$' % (c_title, c_max))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Implementation\n",
    "\n",
    "The implementations of basic thresholds and segmentations is very easy since it is a unary operation of a single image\n",
    "$$ f(I(\\vec{x})) $$\n",
    "In mathematical terms this is called a map and since it does not require information from neighboring voxels or images it can be calculated for each point independently (_parallel_). Filters on the other hand almost always depend on neighboring voxels and thus the calculations are not as easy to seperate. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Implementation Code \n",
    "### Matlab / Python (numpy)\n",
    "The simplist is a single threshold in Matlab: \n",
    "```matlab\n",
    "thresh_img = gray_img > thresh\n",
    "```\n",
    "\n",
    "A more complicated threshold: \n",
    "```\n",
    "thresh_img = (gray_img > thresh_a) & (gray_img < thresh_b)\n",
    "```\n",
    "\n",
    "\n",
    "### Python\n",
    "```python\n",
    "thresh_img = map(lambda gray_val: gray_val>thresh,\n",
    "                gray_img)\n",
    "```\n",
    "\n",
    "***\n",
    "\n",
    "### Java\n",
    "```java\n",
    "boolean[] thresh_img = new boolean[x_size*y_size*z_size];\n",
    "for(int x=x_min;x<x_max;x++)\n",
    "  for(int y=y_min;y<y_max;y++)\n",
    "    for(int z=z_min;z<z_max;z++) {\n",
    "      int offset=(z*y_size+y)*x_size+x;\n",
    "      thresh_img[offset]=gray_img[offset]>thresh;\n",
    "    }\n",
    "```\n",
    "  \n",
    "### In C/C++\n",
    "\n",
    "```c\n",
    "bool* thresh_img = malloc(x_size*y_size*z_size * sizeof (bool));\n",
    "\n",
    "for(int x=x_min;x<x_max;x++)\n",
    "  for(int y=y_min;y<y_max;y++)\n",
    "    for(int z=z_min;z<z_max;z++) {\n",
    "      int offset=(z*y_size+y)*x_size+x;\n",
    "      thresh_img[offset]=gray_img[offset]>thresh;\n",
    "    }\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# [Morphology](http://scikit-image.org/docs/dev/api/skimage.morphology.html)\n",
    "We can now utilize information from neighborhood voxels to improve the results. These steps are called morphological operations. We return to the original image of a cross\n",
    "\n",
    "Like filtering the assumption behind morphological operations are\n",
    "- nearby voxels in __real__ images are related / strongly correlated with one another \n",
    "- noise and imaging artifacts are less spatially correlated. \n",
    "\n",
    "Therefore these imaging problems can be alleviated by adjusting the balance between local and neighborhood values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "nx = 20\n",
    "ny = 20\n",
    "xx, yy = np.meshgrid(np.linspace(-10, 10, nx),\n",
    "                     np.linspace(-10, 10, ny))\n",
    "np.random.seed(2018)\n",
    "cross_im = 1.1*((np.abs(xx) < 2)+(np.abs(yy) < 2)) + \\\n",
    "    np.random.uniform(-1.0, 1.0, size=xx.shape)\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 3.5), dpi=200)\n",
    "ax1.imshow(cross_im, cmap='hot')\n",
    "ax1.set_title('Image')\n",
    "ax2.imshow(cross_im > 0.8)\n",
    "ax2.set_title('Simple Thresholding')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Fundamentals: Neighborhood\n",
    "A neighborhood consists of the pixels or voxels which are of sufficient proximity to a given point. There are a number of possible definitions which largely affect the result when it is invoked.   \n",
    "- A large neighborhood performs operations over larger areas / volumes\n",
    " - Computationally intensive\n",
    " - Can _smooth_ out features\n",
    "- A small neighborhood performs operations over small areas / volumes\n",
    " - Computationally cheaper\n",
    " - Struggles with large noise / filling large holes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The neighborhood is important for a large number of image and other (communication, mapping, networking) processing operations:\n",
    "- filtering\n",
    "- morphological operations\n",
    "- component labeling\n",
    "- distance maps\n",
    "- image correlation based tracking methods\n",
    "\n",
    "It is often called structuring element (or ```selem``` for sort / code), but has exactly the same meaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Fundamentals: Neighbors in 2D\n",
    "For standard image operations there are two definitions of neighborhood. The 4 and 8 adjacent neighbors shown below. Given the blue pixel in the center the red are the 4-adjacent and the red and green make up the 8 adjacent. We expand beyond this to disk, cross, vertical and horizontal lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from skimage.morphology import disk, octagon as oct_func, star\n",
    "\n",
    "\n",
    "def h_line(n):\n",
    "    return np.pad(np.ones((1, 2*n+1)), [[n, n], [0, 0]], mode='constant', constant_values=0).astype(int)\n",
    "\n",
    "\n",
    "def v_line(n):\n",
    "    return h_line(n).T\n",
    "\n",
    "\n",
    "def cross(n):\n",
    "    return ((h_line(n)+v_line(n)) > 0).astype(int)\n",
    "\n",
    "\n",
    "def octagon(n):\n",
    "    return oct_func(n, n)\n",
    "\n",
    "\n",
    "neighbor_functions = [disk, cross, h_line, v_line, star, octagon]\n",
    "sizes = [2, 3, 5]\n",
    "fig, m_axs = plt.subplots(len(neighbor_functions),\n",
    "                          len(sizes), figsize=(12, 20))\n",
    "for c_func, c_axs in zip(neighbor_functions, m_axs):\n",
    "    for c_dim, c_ax in zip(sizes, c_axs):\n",
    "        c_ax.imshow(c_func(c_dim), cmap='bone', interpolation='none')\n",
    "        c_ax.set_title('{} {}'.format(c_func.__name__, c_func(c_dim).shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Erosion and Dilation\n",
    "\n",
    "### Erosion\n",
    "If any of the voxels in the neighborhood are 0/false than the voxel will be set to 0\n",
    "\n",
    "- Has the effect of peeling the surface layer off of an object\n",
    "\n",
    "***\n",
    "\n",
    "### Dilation\n",
    "\n",
    "If any of the voxels in the neigbhorhood are 1/true then the voxel will be set to 1\n",
    "- Has the effect of adding a layer onto an object (dunking an strawberry in chocolate, adding a coat of paint to a car)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Applied Erosion and Dilation\n",
    "\n",
    "### Dilation\n",
    "We can use dilation to expand objects, for example a too-low threshold value leading to disconnected components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from skimage.morphology import binary_dilation, binary_erosion, disk\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 3.5), dpi=200)\n",
    "simple_img = np.eye(5)\n",
    "ax1.imshow(simple_img)\n",
    "ax1.set_title('Original Image')\n",
    "dil_image = binary_dilation(simple_img, disk(1))\n",
    "ax2.imshow(dil_image)\n",
    "ax2.set_title('Dilation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Erosion\n",
    "Erosion performs the opposite task reducing the size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 3.5), dpi=200)\n",
    "ax1.imshow(dil_image)\n",
    "ax1.set_title('Dilated Image')\n",
    "ax2.imshow(binary_erosion(dil_image, disk(1)))\n",
    "ax2.set_title('Erosion')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Opening and Closing\n",
    "\n",
    "### Opening\n",
    "\n",
    "An erosion followed by a dilation operation\n",
    "\n",
    "- Peels a layer off and adds a layer on\n",
    "- Very small objects and connections are deleted in the erosion and do not return the image is thus __open__ed\n",
    "- A cube larger than several voxels will have the exact same volume after (conservative)\n",
    "\n",
    "***\n",
    "\n",
    "### Closing\n",
    "\n",
    "A dilation followed by an erosion operation\n",
    "\n",
    "- Adds a layer and then peels a layer off\n",
    "- Objects that are very close are connected when the layer is added and they stay connected when the layer is removed thus the image is __close__d\n",
    "- A cube larger than one voxel will have the exact same volume after (conservative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from skimage.morphology import binary_dilation, binary_erosion, binary_opening, binary_closing, disk\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import zoom\n",
    "fig, m_axs  = plt.subplots(2, 3, figsize=(15, 10), dpi=200)\n",
    "((ax1, ax2, ax3), (ax4, ax5, ax6)) = m_axs\n",
    "ax4.axis('off')\n",
    "simple_img = np.eye(5)\n",
    "simple_img[2, 2] = 0\n",
    "simple_img += simple_img[::-1]\n",
    "simple_img = zoom(simple_img, 4, order=0)\n",
    "neighborhood = disk(2)\n",
    "ax1.imshow(simple_img)\n",
    "ax1.set_title('Original')\n",
    "\n",
    "ax2.imshow(binary_dilation(simple_img, neighborhood))\n",
    "ax2.set_title('Original->Dilation')\n",
    "\n",
    "ax5.imshow(binary_closing(simple_img, neighborhood))\n",
    "ax5.set_title('Original->Dilation->Erosion\\n(Closing)')\n",
    "\n",
    "\n",
    "ax3.imshow(binary_erosion(simple_img, neighborhood))\n",
    "ax3.set_title('Original->Erosion')\n",
    "\n",
    "ax6.imshow(binary_opening(simple_img, neighborhood))\n",
    "ax6.set_title('Original->Erosion->Dilation\\n(Opening)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Pitfalls with Segmentation\n",
    "\n",
    "### Partial Volume Effect\n",
    "- The [partial volume effect](http://bit.ly/1mW7kdP) is the name for the effect of discretization on the image into pixels or voxels.\n",
    "- Surfaces are complicated, voxels are simple boxes which make poor representations\n",
    "- Many voxels are only partially filled, but only the voxels on the surface\n",
    "- Removing the first layer alleviates issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.ndimage import zoom\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.io import imread\n",
    "%matplotlib inline\n",
    "step_list = [10, 20, 50, 100, 500]\n",
    "fig, m_axs = plt.subplots(1, len(step_list), figsize=(15, 5), dpi=200)\n",
    "for c_ax, steps in zip(m_axs, step_list):\n",
    "    x_lin = np.linspace(-1, 1, steps)\n",
    "    xy_area = np.square(np.diff(x_lin)[0])\n",
    "    xx, yy = np.meshgrid(x_lin, x_lin)\n",
    "    test_img = (np.square(xx)+np.square(yy+0.25)) < np.square(0.75)\n",
    "    c_ax.matshow(test_img)\n",
    "    c_ax.set_title('%dpx\\nVolume Fraction: %2.2f%%' %\n",
    "                   (steps, 100*np.sum(test_img)/np.prod(test_img.shape)))\n",
    "    c_ax.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Rescaling\n",
    "We see the same effect when we rescale images from 500x500 down to 15x15 that the apparent volume fraction changes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "zoom_level = [1, 0.067, 0.039, 0.029, 0.02]\n",
    "fig, m_axs = plt.subplots(2, len(zoom_level), figsize=(15, 5), dpi=200)\n",
    "for (c_ax, ax2), c_zoom in zip(m_axs.T, zoom_level):\n",
    "    c_img = zoom(255.0*test_img, c_zoom, order=1)\n",
    "    c_ax.matshow(c_img)\n",
    "    c_ax.set_title('%dpx - Volume: %2.2f%%' %\n",
    "                   (c_img.shape[0], 100*np.sum(c_img > 0.5)/np.prod(c_img.shape)))\n",
    "    c_ax.axis('off')\n",
    "    ax2.plot(c_img[c_img.shape[0]//2], 'r+-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "livereveal": {
   "autolaunch": true,
   "enable_chalkboard": true,
   "footer": "March 12, 2020 - ETH 227-0966-00L: Quantitative Big Imaging/Basic Segmentation part 2",
   "header": "<table width='100%' style='margin: 0px;'><tr><td align='left'><img src='../common/figures/eth_logo_kurz_pos.svg' style='height:30px;'></td><td align='right'><img src='../common/figures/PSI-Logo.svg' style='height:50px;'></td></tr></table>",
   "scroll": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
