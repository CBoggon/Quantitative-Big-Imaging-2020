{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# ETHZ: 227-0966-00L\n",
    "# Quantitative Big Imaging\n",
    "# April 16, 2019\n",
    "\n",
    "## Bimodal experiments\n",
    "\n",
    "#### Anders Kaestner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (8, 8)\n",
    "plt.rcParams[\"figure.dpi\"] = 150\n",
    "plt.rcParams[\"font.size\"] = 14\n",
    "plt.rcParams['font.family'] = ['sans-serif']\n",
    "plt.rcParams['font.sans-serif'] = ['DejaVu Sans']\n",
    "plt.style.use('ggplot')\n",
    "sns.set_style(\"whitegrid\", {'axes.grid': False})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Literature / Useful References\n",
    "\n",
    "### Books\n",
    "- John C. Russ, \"The Image Processing Handbook\",(Boca Raton, CRC Press)\n",
    " - Available [online](http://dx.doi.org/10.1201/9780203881095) within domain ethz.ch (or proxy.ethz.ch / public VPN) \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Typical neutron imaging experiment and challenges\n",
    "\n",
    "<table>\n",
    "<col width=\"400px\" />\n",
    "<tr><th>Hydrology in soil and geology</th><th>Cultural heritage</th></tr>\n",
    "<tr>\n",
    "<td>\n",
    "<center>\n",
    "<img src=\"../common/figures/soil.png\" style=\"height:200px\" />\n",
    "</center>        \n",
    "    \n",
    "- Segmentation accuracy\n",
    "- Estimate water content\n",
    "\n",
    "</td>\n",
    "<td>\n",
    "<center>\n",
    "<img src=\"../common/figures/buddha_neutron.png\" style=\"height:200px\" />\n",
    "</center>\n",
    "    \n",
    "- Segmentation accuracy\n",
    "- Material classification\n",
    "        \n",
    "</td>  \n",
    "</tr>\n",
    "<tr><th>Building materials</th><th>Materials science</th></tr>\n",
    "<tr>\n",
    "<td>\n",
    "<center>    \n",
    "<img src=\"../common/figures/CapillaryRise.png\" style=\"height:200px\" />\n",
    "</center>        \n",
    "    \n",
    "- Estimate water content\n",
    "- Dimensional changes\n",
    "\n",
    "</td>\n",
    "<td>\n",
    "<center>    \n",
    "<img src=\"../common/figures/weld.png\" style=\"height:200px\" />\n",
    "</center>\n",
    "    \n",
    "- Penetration power\n",
    "- Ambiguous readings\n",
    "        \n",
    "</td>  \n",
    "</tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Why multiple modalities?\n",
    "Reasons to select or reject a specific imaging method\n",
    "\n",
    "### Advantages of a specific method\n",
    "\n",
    "- Good transmission\n",
    "- Good contrast\n",
    "- Relevant features visible\n",
    "- Materials can be identified\n",
    "\n",
    "### Disadvantages\n",
    "- Low transmission\n",
    "- Low contrast\n",
    "- Not all features visible\n",
    "- Ambiguous response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# The aim of multimodal imaging\n",
    "### Purpose of multi-modality\n",
    "Match the advantages of each method against the disadvantages of the other methods to obtain more information than using each method individually.\n",
    "\n",
    "1. Extend range of operation.\n",
    "2. Extend spatial and temporal coverage.\n",
    "3. Reduce uncertainty.\n",
    "4. Increase reliability.\n",
    "5. Robust system performance.\n",
    "\n",
    "<img src=\"../common/figures/multispectral_goggles.png\" style=\"height:200px\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "# The components of imaging\n",
    "\n",
    "<img src=\"../common/figures/imaging_balls.png\" style=\"height:500px\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Some considered modalities -  Neutrons and X-rays\n",
    "\n",
    "<table>\n",
    "<cols width=\"700px\" />\n",
    "<tr><th>Neutrons</th><th>X-rays</th></tr>\n",
    "<tr>\n",
    "<td>\n",
    "<center>\n",
    "<img src=\"../common/figures/camera_neutrons.png\" style=\"height:200px\" />\n",
    "</center>        \n",
    "<center>\n",
    "<img src=\"../common/figures/periodicN.png\" style=\"height:400px\" />\n",
    "</center>     \n",
    "</td>\n",
    "<td>\n",
    "<center>\n",
    "<img src=\"../common/figures/camera_xrays.png\" style=\"height:200px\" />\n",
    "</center>\n",
    "    <center>\n",
    "<img src=\"../common/figures/periodicX.png\" style=\"height:400px\" />\n",
    "</center>\n",
    "</td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Some considered modalities - X-ray and MRI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Some considered modalities - Grating interferometry\n",
    "\n",
    "<table>\n",
    "<cols width=\"400px\" />\n",
    "    <tr><th>Transmission</th><th>Differential phase</th><th>Dark field</th></tr>\n",
    "<tr>\n",
    "<td>\n",
    "<center>\n",
    "<img src=\"../common/figures/nGI_TI.png\" style=\"height:200px\" />\n",
    "</center>        \n",
    "</td>\n",
    "<td>\n",
    "<center>\n",
    "<img src=\"../common/figures/nGI_DPC.png\" style=\"height:200px\" />\n",
    "</center>\n",
    "    \n",
    "</td>  \n",
    "<td>\n",
    "<center>\n",
    "<img src=\"../common/figures/nGI_DFI.png\" style=\"height:200px\" />\n",
    "</center>\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "- Data comparable on pixel level\n",
    "- Non-linear relation between the variables.\n",
    "- Improved estimation schemes using iterative process\n",
    "- Physical interpretation/motivation to fuse?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Some considered modalities - Spectroscopic imaging\n",
    "<img src=\"../common/figures/ES_Fe.png\" style=\"height:400px\" />\n",
    "\n",
    "- Material analysis\n",
    "- Selector calibration\n",
    "\n",
    "S. Peetermans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Other modalities and dimensionality\n",
    "#### The information can also be provided as few localized points \n",
    "- Single spots\n",
    "- Surface information\n",
    "- Single radiographs vs CT data\n",
    "\n",
    "#### to provide\n",
    "\n",
    "- Temperature\n",
    "- Flowrate\n",
    "- Pressure\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Image fusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is data fusion?\n",
    "\t\\begin{block}{Definition}\n",
    "\t\tThe theory, techniques and tools which are used for combining sensor data, or data derived from sensory data, into a common representational format.\n",
    "\t\\end{block}\n",
    "\t\n",
    "\t\\begin{block}{Aim}\n",
    "\t\tTo improve the quality of the information, so that it is, in some sense, better than would be possible if the data sources were used individually.\n",
    "\t\\end{block}\n",
    "\t\\vfill\n",
    "\t\\hfill\\footnotesize\\cite{mitchell2012_datafusion}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    \n",
    "# Fusion approaches -- no golden recipe\n",
    "\\vskip1em\n",
    "\\begin{block}{Fusion strategies}\n",
    "\\begin{description}\n",
    "\\item[Multivariate fusion] All data are combined using the same concept.\n",
    "\\item[Augmented fusion] Modalities have different functions in the fusion process.\n",
    "\\item[Artifact reduction by fusion] The second modality can be used to fill in the blanks.\n",
    "\\item[Combination] One method may not give the final result -- combination \n",
    "\\end{description}\n",
    "\\end{block}\n",
    "\n",
    "\\begin{block}{Select strategy}\n",
    "The fusion strategy determined by:\n",
    "\\begin{itemize}\n",
    "\\item Sample composition \n",
    "\\item Experiment objectives \n",
    "\\item Condition of the data\n",
    "\\end{itemize}\n",
    "\\end{block}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Levels of fusion\n",
    "\\begin{tabular}{ccl}\n",
    "Input & Output & Description\\\\\n",
    "\\hline\\\\\n",
    "Data & Data & Output Input data is smoothed/filtered\\\\\\\\\n",
    "Data & Feature & \\begin{minipage}{0.6\\textwidth}Features are generated from the input data, e.g. edge detection in an image.\\end{minipage}\\\\\\\\\n",
    "Feature & Feature & \\begin{minipage}{0.6\\textwidth}\n",
    "Input features are reduced in number, or new features are generated by fusing input features.\n",
    "\\end{minipage} \\\\\\\\\n",
    "Feature & Decision & \\begin{minipage}{0.6\\textwidth}\n",
    "Input features are fused together to give output decision.\n",
    "\\end{minipage} \n",
    "\\\\\\\\\n",
    "Decision & Decision & \\begin{minipage}{0.6\\textwidth}\n",
    "Multiple input decisions are fused together to give a final output decision.\n",
    "\\end{minipage} \n",
    "\\end{tabular}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image fusion workflow\n",
    "\\includegraphics[width=\\textwidth]{imagefusion_process.pdf}\n",
    "\\vfill\\hfill\\footnotesize\\cite{goshtasby2012_registration},\\cite{mitchell2010_imagefusion}\n",
    "}\n",
    "\n",
    "\\frame<beamer:1>{\\frametitle{Catastrophic fusion}\n",
    "\t\\begin{block}{Definition}\n",
    "\t\tThe combination perform worse than the individual modalities.\n",
    "\t\t\\vskip1em\n",
    "\t\tThis can be caused by\n",
    "\t\t\\begin{itemize}\n",
    "\t\t\t\\item Selection of the wrong variables.\n",
    "\t\t\t\\item Too complex combination.\n",
    "\t\t\t\\item Sensor information canceling each other.\n",
    "\t\t\\end{itemize}\n",
    "\t\\end{block}\n",
    "\t\\vfill\n",
    "\t\\hfill\\includegraphics[width=0.5\\textwidth]{bad_soup.png}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image registration\n",
    "\t\\begin{block}{The process}\n",
    "\t\tA series of affine transformations to bring images on the same grid.\n",
    "\t\t\\centering\n",
    "\t\t\\includegraphics[width=0.8\\textwidth]{figures/manualreg.pdf}\n",
    "\t\\end{block}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Registration considerations\n",
    "Registration is an optimization problem with many local minima.\n",
    "\\begin{itemize}\n",
    "\t\\item Manual or guided registration\n",
    "\t\\begin{itemize}\n",
    "\t\t\\item Perform the full transformation manually\n",
    "\t\t\\item Identify land marks, points, lines, planes\n",
    "\t\t\\item Provide a coarse preregistration\n",
    "\t\\end{itemize}\n",
    "\t\\item Automatic registration\n",
    "\t\\begin{itemize}\n",
    "\t\t\\item Iterative process \n",
    "\t\t\\item Metrics\n",
    "\t\t\\item Multi-modality loose common landmarks \n",
    "\t\\end{itemize}\n",
    "\\end{itemize}\n",
    "\\vfill\\hfill\\footnotesize\\cite{goshtasby2012_registration}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Registration and covisualization\n",
    "Use e.g. VG Studio to \n",
    "\\begin{itemize}\n",
    "\\item Register data sets\n",
    "\\item Interactive guided segmentation of the separate data sets.\n",
    "\\end{itemize}\n",
    "\\begin{columns}[T]\n",
    "\\begin{column}{0.4\\textwidth}\n",
    "\\begin{block}{Neutrons}\n",
    "\\centering\n",
    "\\includegraphics[width=0.9\\textwidth]{swordN.png}\n",
    "\\end{block}\n",
    "\\end{column}\n",
    "\\begin{column}{0.4\\textwidth}\n",
    "\\begin{block}{X-rays}\n",
    "\\centering\n",
    "\\includegraphics[width=0.9\\textwidth]{swordX.png}\n",
    "\\end{block}\n",
    "\\end{column}\n",
    "\\end{columns}\n",
    "\\vfill\\hfill\\footnotesize\n",
    "\\cite{mannes2015_NXCultHer}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Radiography\n",
    "Equation system for the transmission \n",
    "\\begin{eqnarray}\n",
    "\\sum_{i=1}^{N}\\,\\Sigma_i\\,x_i&=&q_N\\nonumber\\\\\n",
    "\\sum_{i=1}^{N}\\,\\mu_i\\,x_i&=&q_X\n",
    "\\end{eqnarray}\n",
    "\n",
    "- attn coeff known $\\rightarrow$ estimate lengths.\n",
    "- More pixels $\\rightarrow$ more materials.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computed tomography\n",
    "\n",
    "- Voxels represent local attenuation coefficients.\n",
    "- Linear eq system can be set up also here.\n",
    "\n",
    "$\\rightarrow$ Determine subpixel mixing information.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bimodal Segmentation - Single modality histogram\n",
    "\\centering\n",
    "\\includegraphics[width=\\textwidth]{overlapping_classesA.png}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two modalities separate\n",
    "### Modality A\n",
    "\\includegraphics[width=\\textwidth]{overlapping_classesA.png}\n",
    "### Modality B\n",
    "\\includegraphics[width=\\textwidth]{overlapping_classesB.png}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bivariate histogram\n",
    "\\centering\n",
    "\\includegraphics[width=\\textwidth]{bivariate_classes.png}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: Roots in soil\n",
    "\\includegraphics[width=\\textwidth]{figures/root_slices.pdf}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bivariate histogram of roots\n",
    "\\includegraphics[height=0.8\\textheight]{figures/root_histogram.png}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification methods\n",
    "## Data\n",
    "- Images from $M$ modalities $f_1, \\ldots, f_M$\n",
    "- Registered\n",
    "- Artifact corrected\n",
    "\n",
    "## Classes\n",
    "The $N$ classes are described by: \n",
    "$$\\begin{eqnarray}\n",
    "\\mathcal{H}_1 : p(\\mathbf{\\mu}_1,\\Sigma_1)\\nonumber\\\\\n",
    "\\mathcal{H}_2 : p(\\mathbf{\\mu}_2,\\Sigma_2)\\nonumber\\\\\n",
    "\\vdots\\nonumber\\\\\n",
    "\\mathcal{H}_N : p(\\mathbf{\\mu}_N,\\Sigma_N)\\nonumber\n",
    "\\end{eqnarray}\n",
    "$$\n",
    "\n",
    "## Gaussian mixture model\n",
    "\n",
    "With Gaussian distribution we can describe the bivariate histogram using:\n",
    "$$p(\\theta)=\\sum_{1}^{N} \\phi\\,\\mathcal{N}(\\mathbf{\\mu}_i,\\Sigma_i)\n",
    "\n",
    "\\cite{duda01}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian mixture model\n",
    "### Bivariate data\n",
    "\\includegraphics[width=\\textwidth]{figures/mixingmodels/bivardata.pdf}\n",
    "\n",
    "### Gaussian mixture model fitting\n",
    "\\includegraphics[width=\\textwidth]{figures/mixingmodels/GMM_fits.pdf}\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification distances\n",
    "For a set of multivariate normal distributions $p_i=\\mathcal{N}(\\mu_i,\\Sigma_i)$\n",
    "#### Euclidean\n",
    "$$D_{E}=\\sqrt{(x-\\mu_1)^T \\cdot (x-\\mu_1)} $$\n",
    "\n",
    "#### Mahanalubis\n",
    "Distance from class $i$ to point $x$\n",
    "$$D_M=\\sqrt{\\left(x-\\mu_i\\right)^T \\Sigma_i \\left(x-\\mu_i\\right)}$$\n",
    "\n",
    "#### Bhattacharia\n",
    "Distance between two classes \n",
    "$$D_B=\\frac{1}{8}\\left(\\mu_1-\\mu_2\\right)^T \\Sigma \\left(\\mu_1-\\mu_2\\right) + \\frac{1}{2}\\ln\\left(\\frac{|\\Sigma|}{\\sqrt{|\\Sigma_1|\\cdot|\\Sigma_2|}}\\right)$$\n",
    "\n",
    "\n",
    "Assign the point to the class with shortest distance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmentation by Euclidean distance\n",
    "\\includegraphics[height=0.8\\textheight]{figures/root_decision.pdf}\n",
    "\\vfill\\hfill\\footnotesize\\cite{kaestner2016_itmnrnx}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with attenuation coefficients\n",
    "\n",
    "### Beer-Lamberts law\n",
    "\n",
    "$$ I=I_0\\,e^{-\\frac{\\rho}{A}\\,N_A\\,\\sigma\\,x} $$\n",
    "- $\\rho$ Material denstity\n",
    "- $A$ Atomic weight\n",
    "- $\\sigma$ microscopic cross section\n",
    "     - Probability of interaction\n",
    "     - modality dependent\n",
    "\n",
    "- $x$ propagation length\n",
    "\n",
    "### Equation system\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "\\sum_{i=1}^{N}\\,\\Sigma_i\\,x_i&=&q_N\\nonumber\\\\\n",
    "\\sum_{i=1}^{N}\\,\\mu_i\\,x_i&=&q_X\n",
    "\\end{eqnarray}\n",
    "$$\n",
    "- attn coeff known $\\rightarrow$ estimate lengths.\n",
    "- More pixels $\\rightarrow$ more materials.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "rise": {
   "autolaunch": true,
   "enable_chalkboard": true,
   "footer": "April 30, 2020 - ETH 227-0966-00L: Quantitative Big Imaging/BimodalExperiments",
   "header": "<table width='100%' style='margin: 0px;'><tr><td align='left'><img src='../common/figures/eth_logo_kurz_pos.svg' style='height:30px;'></td><td align='right'><img src='../common/figures/PSI-Logo.svg' style='height:50px;'></td></tr></table>",
   "scroll": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
